<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<title>Soniweb: An Experiment in Web Traffic Sonification and Ambisonics</title>
		<meta name="description" content="A project created for the MCT Master&#39;s program&#39;s sonification course">
		<meta name="generator" content="Eleventy v3.0.0">

		<link rel="preload" as="font" href="/font/Switzer-Variable.subset.woff2" crossorigin>
		<link rel="preload" as="font" href="/font/Rag-Regular.subset.woff2" crossorigin>
		<link rel="alternate" href="/feed/feed.xml" type="application/atom+xml" title="Jackson">
		<link rel="alternate" href="/feed/feed.json" type="application/json" title="Jackson">
		<style>
			/*
  Josh's Custom CSS Reset
  https://www.joshwcomeau.com/css/custom-css-reset/
*/
*,
*::before,
*::after {
	box-sizing: border-box;
}
* {
	line-height: calc(1em + 0.725rem);
	margin: 0;
}
body {
	-webkit-font-smoothing: antialiased;
}
img,
picture,
video,
canvas,
svg {
	display: block;
	max-width: 100%;
}
input,
button,
textarea,
select {
	font: inherit;
}
p,
h1,
h2,
h3,
h4,
h5,
h6 {
	overflow-wrap: break-word;
	margin: revert;
}
#root,
#__next {
	isolation: isolate;
}

		:root {
	--color-bg: white;
	--color-gray-20: #333333;
	--color-gray-50: #7f7f7f;
	--color-gray-90: #e5e5e5;
	--font-family: "Rag", -apple-system, system-ui, sans-serif;
	--font-family-monospace: Consolas, Menlo, Monaco, Andale Mono WT, Andale Mono,
		Lucida Console, Lucida Sans Typewriter, DejaVu Sans Mono,
		Bitstream Vera Sans Mono, Liberation Mono, Nimbus Mono L, Courier New,
		Courier, monospace;
	--syntax-tab-size: 2;
	--noise-img: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 600 600'%3E%3Cfilter id='a'%3E%3CfeTurbulence type='fractalNoise' baseFrequency='.65' numOctaves='3' stitchTiles='stitch'/%3E%3C/filter%3E%3Crect width='100%25' height='100%25' filter='url(%23a)'/%3E%3C/svg%3E");
	--noise-opacity: 0.2;
	/* Josh Comeau shadows */
	--shadow-color: 0deg 0% 0%;
	--shadow-elevation-low: 0px 0.2px 0.2px hsl(var(--shadow-color) / 0.16),
		0.1px 0.8px 0.8px -3px hsl(var(--shadow-color) / 0.13);
	--shadow-elevation-medium: 0px 0.2px 0.2px hsl(var(--shadow-color) / 0.15),
		0.1px 1px 1.1px -1.5px hsl(var(--shadow-color) / 0.13),
		0.3px 4.2px 4.4px -3px hsl(var(--shadow-color) / 0.11);
	--shadow-elevation-high: 0px 0.2px 0.2px hsl(var(--shadow-color) / 0.14),
		0.1px 1.3px 1.4px -0.6px hsl(var(--shadow-color) / 0.13),
		0.2px 2.8px 2.9px -1.2px hsl(var(--shadow-color) / 0.12),
		0.5px 5.7px 6px -1.8px hsl(var(--shadow-color) / 0.11),
		0.9px 10.9px 11.5px -2.4px hsl(var(--shadow-color) / 0.11),
		1.5px 19.3px 20.3px -3px hsl(var(--shadow-color) / 0.1);
	--nav-height: 4rem; /* Default height to lower for header*/
	color-scheme: light dark;
}

/* Both for system and user preference */
:root[data-theme="dark"],
.dark-mode {
	--color-bg: black;
	--color-gray-20: #cccccc;
	--color-gray-50: #808080;
	--color-gray-90: #1a1a1a;
	--noise-opacity: 0.1;
	color-scheme: dark;
}

@font-face {
	font-weight: 500;
	src: url("/font/Switzer-Variable.subset.woff2") format("woff2");
	font-family: "Switzer";
	font-display: swap;
	/* font-variation-settings: "wght" 400; */
}
@font-face {
	font-style: normal italic;
	font-weight: 400;
	src:
		url("/font/Rag-Regular.subset.woff2") format("woff2"),
		url("/font/Rag-Italic.subset.woff2") format("woff2"),
		url("/font/Rag-Bold.subset.woff2") format("woff2"),
		url("/font/Rag-BoldItalic.subset.woff2") format("woff2");
	font-family: "Rag";
	font-display: swap;
}

/* Only set the overflow to the root */
html {
	overflow-x: hidden;
}
html,
body {
	width: 100%;
	padding: 0;
	background-color: Canvas;
	background-color: transparent;
	color: CanvasText;
	font-family: var(--font-family);
}
body {
	display: flex;
	justify-content: center;
	max-width: none;
}

.layout-wrapper {
	display: flex;
	width: 100%;
	max-width: calc(40rem + 200px + 2rem);
	min-height: 100vh;
}

main {
	width: 100%;
	max-width: 40rem;
	padding: 1rem;

	& :first-child {
		margin-top: 0;
	}

	/* Add a margin for when chat bubble is absolute */
	&:where(.chat-active) {
		margin-top: 3rem;
	}
}

/* Typography */
h1,
h2,
h3 {
	margin-top: 1.5rem;
	margin-bottom: 1rem;
}

h1,
h2,
h3,
.letter {
	text-wrap: balance;
	width: fit-content;
	font-family: "Switzer";
}

/* https://www.a11yproject.com/posts/how-to-hide-content/ */
.visually-hidden {
	clip: rect(0 0 0 0);
	position: absolute;
	width: 1px;
	height: 1px;
	overflow: hidden;
	white-space: nowrap;
	clip-path: inset(50%);
}

p:last-child {
	margin-bottom: 0;
}

.links-nextprev {
	margin-top: 1rem;
	padding: 1rem 0;
	border-top: 1px dashed var(--color-gray-20);
	list-style: none;
}

table {
	margin: 1rem 0;
}
table td,
table th {
	padding-right: 1rem;
}

pre {
	border-radius: 0.25rem;
	box-shadow: var(--shadow-elevation-low);
}
pre,
code {
	font-family: var(--font-family-monospace);
}
pre:not([class*="language-"]) {
	-moz-tab-size: var(--syntax-tab-size);
	-o-tab-size: var(--syntax-tab-size);
	-webkit-hyphens: none;
	-ms-hyphens: none;
	margin: 0.5rem 0;
	line-height: 1.375; /* 22px /16 */
	hyphens: none;
	direction: ltr;
	text-align: left;
	white-space: pre;
	word-break: normal;
	word-spacing: normal;
	tab-size: var(--syntax-tab-size);
}
code {
	word-break: break-all;
}

/* Header */
.home-link {
	margin-right: 2rem;
	font-weight: 700;
	font-size: 1rem; /* 16px /16 */
}
.home-link:link:not(:hover) {
	text-decoration: none;
}

/* Nav */
nav {
	position: relative;
	width: 100%;
	list-style: none;
}
.nav-item {
	display: inline-block;
	padding: 0.25rem 0;
}
.nav-item a[href]:not(:hover) {
	text-decoration: none;
}
.nav a[href][aria-current="page"] {
	text-decoration: underline;
}

/* Posts list */
.postlist {
	padding: 0;
	list-style: none;
}

/* Each item in a po */
.postlist-item {
	display: flex;
	position: relative;
	flex-wrap: wrap;
	align-items: baseline;
	margin-bottom: 1rem;
	padding-left: 1.5rem; /* Add left padding to make room for the arrow */

	&::before {
		position: absolute;
		top: 0.2rem;
		left: 0;
		margin-right: 0.5rem;
		transform: scale(1);
		content: "\2192"; /* Default to arrow */
		color: var(--color-gray-20);
		filter: saturate(100%);
		transition: all 0.5s ease-out;
	}

	&[data-emoji]::before {
		content: attr(data-emoji);
	}

	&:hover::before,
	&:focus-within::before {
		animation: pulseSat 2s linear infinite;
	}

	&:not(:hover)::before {
		transform: scale(1);
		animation: none;
		filter: saturate(100%);
	}

	.postlist-date::after {
		visibility: hidden;
		position: absolute;
		max-width: calc(100% - 12rem);
		padding-left: 1rem;
		overflow: hidden;
		content: attr(data-tooltip);
		color: var(--color-gray-20);
		text-overflow: ellipsis;
		white-space: nowrap;
		opacity: 0;
		transition:
			opacity 0.3s ease,
			visibility 0.3s ease;
	}

	&:has(.postlist-link:hover) .postlist-date::after {
		visibility: visible;
		opacity: 1;
	}

	&-active .postlist-link {
		font-weight: bold;
	}
}

@keyframes pulseSat {
	0%,
	50%,
	100% {
		transform: scale(1);
		filter: saturate(100%);
	}
	25% {
		transform: scale(0.8);
		filter: saturate(50%);
	}
	75% {
		transform: scale(1.2);
		filter: saturate(150%);
	}
}
.postlist-date {
	color: var(--color-gray-20);
	font-size: 0.8125rem; /* 13px /16 */
	word-spacing: -0.5px;
}
.postlist-link {
	flex-basis: 100%;
	font-weight: 700;
	font-size: 1.1875rem; /* 19px /16 */
	text-decoration-thickness: 1px;
	text-underline-position: from-font;
	text-underline-offset: 0;
}

/* Tags */
.post-tag {
	display: inline-flex;
	align-items: center;
	justify-content: center;
	font-style: italic;
	text-transform: capitalize;
}
.postlist-item > .post-tag {
	align-self: center;
}

/* Tags list */
.post-metadata {
	display: inline-flex;
	flex-wrap: wrap;
	margin: 0;
	padding: 0;
	gap: 0.5rem;
	list-style: none;
}
.post-metadata time {
	margin-right: 1rem;
}

/* Direct Links / Markdown Headers */
.header-anchor {
	margin-left: 0.1rem;
	font-style: normal;
	text-decoration: none;
}
a[href].header-anchor,
a[href].header-anchor:visited {
	color: transparent;
}
a[href].header-anchor:focus,
a[href].header-anchor:hover {
	text-decoration: underline;
}
a[href].header-anchor:focus,
:hover > a[href].header-anchor {
	color: #aaa;
}

h2 + .header-anchor {
	font-size: 1.5rem;
}

/* Figures */
figure {
	margin: 1rem 0;
}
figure > * {
	max-width: 100%;
	margin: 0 auto;
}
/* All images & videos should be in a figure */
figure :first-child {
	border-radius: 0.25rem;
	box-shadow: var(--shadow-elevation-low);
}

figcaption {
	margin-top: 0.5rem;
	color: var(--color-gray-20);
	text-align: center;
}

blockquote {
	padding-left: 1rem;
	border-left: 2px solid ButtonFace;
}

/* Talk bubble styling */
.nav-phrase {
	display: none;
	width: 100%;
	padding: 0 0.5rem;
	cursor: text;
}

.nav-bubble {
	display: flex;
	position: absolute;
	align-items: center;
	justify-content: space-between;
	width: calc(100% - 2.5rem);
	margin: 0;
	padding: calc(0.25rem - 1px);
	transform: translateY(calc(var(--item-top) - 12px));
	border: 1px solid var(--color-gray-90);
	border-radius: 0.25rem;
	background: ButtonFace;
	transition: transform 0.3s ease;

	&:before,
	&:after {
		position: absolute;
		top: 10px;
		right: -7.5px;
		width: 0;
		height: 0;
		border: 8px solid transparent;
		border-right: 0;
		content: "";
	}

	&:before {
		right: -9px;
		border-left-color: var(--color-gray-90);
	}

	&:after {
		border-left-color: ButtonFace;
	}

	/* Reset position when chat is active */
	&:where(.chat-active) {
		transform: none;
	}
}

/* Talk bubble movement */
header {
	/* We need to add 1 to the active item to account for the first item */
	--item-top: calc(12px + var(--nav-item-active, 1) * var(--nav-item-height));
	--nav-item-height: 36px;
	z-index: 1; /* Ensure the header is above other elements */

	position: sticky;
	top: 0;
	align-items: start;
	justify-content: end;
	width: 200px;
	height: 100vh;
	padding: 1rem;

	&:not(:has(+ .chat-active)) {
		&:has(.nav-item:nth-child(n):hover) {
			--n: var(--n);
			--item-top: calc(12px + (var(--n) - 1) * var(--nav-item-height));
		}
		&:has(.nav-item:nth-child(1):hover) {
			--n: 1;
		}
		&:has(.nav-item:nth-child(2):hover) {
			--n: 2;
		}
		&:has(.nav-item:nth-child(3):hover) {
			--n: 3;
		}
		&:has(.nav-item:nth-child(4):hover) {
			--n: 4;
		}
		&:has(.nav-item:nth-child(5):hover) {
			--n: 5;
		}
	}
}

.side-nav {
	display: flex;
	justify-content: center;
	width: 100%;
	padding-right: 2rem;
}

.nav-list {
	display: flex;
	z-index: 1;
	flex-direction: column;
	width: 100%;
	margin: 0;
	padding-right: 1rem;
	padding-inline-start: 0;
	list-style: none;
	text-align: right;
}

.theme-toggle {
	position: relative;
	right: -2.25rem;
	align-self: flex-start;
	margin-left: auto;
	transition: transform 0.3s ease;
}

#chat-toggle {
	cursor: pointer;
}

/* Dark mode toggle styles */
#dark-mode-toggle {
	display: none;
}

#dark-mode-toggle + label {
	border: none;
	background: none;
	font-size: 1rem;
	cursor: pointer;
}

#dark-mode-toggle + label::before {
	content: "🐓";
}

#dark-mode-toggle:checked + label::before {
	content: "🐸";
}

@media (prefers-color-scheme: dark) {
	#dark-mode-toggle:not(:checked) + label::before {
		content: "🐓";
	}
	#dark-mode-toggle:checked + label::before {
		content: "🐸";
	}
}

:root:has(#dark-mode-toggle:checked) {
	color-scheme: dark;
}

:root:has(#dark-mode-toggle:not(:checked)) {
	color-scheme: light;
}

/* Chat bubble related */
#user-input {
	width: 100%;
	/* Mozilla? */
	padding: 0;
	border: none;
	outline: none;
	background: none;
	color: inherit;
	font-size: inherit;
	font-family: inherit;
}

#user-input::placeholder,
.waiting {
	color: var(--color-gray-50);
	opacity: 0.7;
}

#chat-form {
	width: 100%;
}

#chat-form button {
	display: none;
}

@keyframes ellipsis {
	0% {
		content: ".";
	}
	33% {
		content: "..";
	}
	66% {
		content: "...";
	}
}

.waiting::after {
	display: inline-block;
	width: 1rem;
	content: ".";
	text-align: left;
	animation: ellipsis 1s infinite;
}

/* Chat reset */
.chat-reset {
	display: none;
	position: relative;
	align-self: flex-start;
	padding: 0 0.5rem;
	border: none;
	background: none;
	color: gray;
	cursor: pointer;
}

/* Add shadow to nav bubble */
.nav-bubble {
	box-shadow: var(--shadow-elevation-low);
}
.nav-bubble.chat-active {
	position: absolute;
	box-shadow: var(--shadow-elevation-medium);
}

.nav-bubble.chat-active .chat-reset {
	display: inline-block;
}

/* Only do nav switch on wide screens */
@media (min-width: 840px) {
	.nav-bubble {
		&:where(.chat-active) {
			/* left: calc(50% + 200px); */
			/* width: calc(640px - 200px); */
			left: calc(200px);
			width: calc(640px - 4.5rem);
		}

		&:where(.chat-active) > * {
			display: inline-block;
		}
	}
}

/* For mobile view */
@media (max-width: 839px) {
	/* Switch side nav off */
	.side-nav {
		display: none;
	}

	/* Mobile */
	.nav-phrase {
		display: inline-block;
	}

	body {
		justify-content: inherit;
		max-width: 40rem;
		margin: 0 auto;
		padding: 0;
	}

	.layout-wrapper {
		display: initial;
		max-width: initial;
	}

	main {
		max-width: initial;

		/* Add a margin for when chat bubble is absolute */
		/* Right now we have header relative with 1rem top margin */
		/* TODO: There's definitely some better way to handle this */
		&:where(.chat-active) {
			margin-top: 2rem;
		}
	}

	header {
		position: relative;
		width: 100%;
		max-width: 640px;
		height: initial;
		padding-bottom: 0;
		gap: 1rem 0.5rem;
	}

	nav {
		flex-direction: column;
	}

	.nav-bubble {
		position: relative;
		left: initial;
		transform: none; /* Reset the transform */
	}
}

/* Util */
.line-clamp {
	-webkit-box-orient: vertical;
	display: -webkit-box;
	-webkit-line-clamp: 2;
	overflow: hidden;
}

.noise-container {
	z-index: -1;
	position: fixed;
	top: 0;
	left: 0;
	width: 100%;
	height: 100%;
	background-image: var(--noise-img);
	background-size: 182px;
	background-repeat: repeat;
	opacity: var(--noise-opacity);
	pointer-events: none;
}

/* Spotify widget */
.spotify-widget img {
	display: inline-block;
	border-radius: 0.25rem;
	box-shadow: var(--shadow-elevation-low);
}

/* Sidebar progress bar */
.progress-bar {
	position: fixed;
	top: 0;
	left: 0;
	width: 0.5rem;
	height: 100vh;
	transform: scaleY(0);
	transform-origin: 0 0;
	background-color: var(--color-gray-50);
}

@supports (animation-timeline: scroll()) {
	html {
		-ms-overflow-style: none; /* Internet Explorer 10+ */
		scrollbar-width: none; /* Firefox */
	}

	html::-webkit-scrollbar {
		display: none; /* Chrome, Safari, and Opera */
		width: 0;
		height: 0;
	}

	.progress-bar {
		animation-timeline: scroll(root block);
		animation-range: entry 0% cover 100%;
		animation: grow-progress linear;
	}

	@keyframes grow-progress {
		to {
			transform: scaleY(1);
		}
	}
}

/* Citation */
.citation {
	margin-bottom: 1rem;
	padding-left: 2rem;
	text-indent: -2rem;
}

.citation p {
	margin: 0;
}

/* Search results */
#search-results {
	max-height: 50vh;
	overflow-y: auto;
}
#search-results:has(.search-result) {
	margin-top: 0.25rem;
	border-top: 1px solid var(--color-gray-90);
}

.search-result {
	--border-width: 0px;
	display: block;
	padding: 0.5rem 1rem;
	border-bottom: 1px solid var(--color-gray-90);
	background: linear-gradient(var(--color-gray-50), var(--color-gray-50))
		left/var(--border-width) 100% no-repeat;
	color: inherit;
	text-decoration: none;
	transition: 0.3s ease;
	transition-property: background-size, background-color;
}

.search-result:hover {
	--border-width: 3px;
	background-color: var(--color-gray-90);
}

.search-result a {
	color: var(--color-gray-20);
	font-weight: bold;
	text-decoration: none;
}

.search-result p {
	margin: 0;
	color: var(--color-gray-50);
}

/* Post gradient title */
.gradient-underline {
	z-index: -1;
	position: absolute;
	top: 0;
	right: 0;
	left: 0;
	height: 10vh;
	pointer-events: none;
}

.gradient-underline::before {
	position: absolute;
	top: 0;
	right: 0;
	bottom: 0;
	left: 0;
	content: "";
}


		
		
			/* PrismJS 1.29.0
https://prismjs.com/download.html#themes=prism-tomorrow&languages=markup+css+clike+javascript+bash+python */
code[class*=language-],pre[class*=language-]{color:#ccc;background:0 0;font-family:Consolas,Monaco,'Andale Mono','Ubuntu Mono',monospace;font-size:1em;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto}:not(pre)>code[class*=language-],pre[class*=language-]{background:#2d2d2d}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal}.token.block-comment,.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#999}.token.punctuation{color:#ccc}.token.attr-name,.token.deleted,.token.namespace,.token.tag{color:#e2777a}.token.function-name{color:#6196cc}.token.boolean,.token.function,.token.number{color:#f08d49}.token.class-name,.token.constant,.token.property,.token.symbol{color:#f8c555}.token.atrule,.token.builtin,.token.important,.token.keyword,.token.selector{color:#cc99cd}.token.attr-value,.token.char,.token.regex,.token.string,.token.variable{color:#7ec699}.token.entity,.token.operator,.token.url{color:#67cdcc}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}.token.inserted{color:green}

			lite-youtube {
    background-color: #000;
    position: relative;
    display: block;
    contain: content;
    background-position: center center;
    background-size: cover;
    cursor: pointer;
    max-width: 720px;
}

/* gradient */
lite-youtube::before {
    content: attr(data-title);
    display: block;
    position: absolute;
    top: 0;
    /* Pixel-perfect port of YT's gradient PNG, using https://github.com/bluesmoon/pngtocss plus optimizations */
    background-image: linear-gradient(180deg, rgb(0 0 0 / 67%) 0%, rgb(0 0 0 / 54%) 14%, rgb(0 0 0 / 15%) 54%, rgb(0 0 0 / 5%) 72%, rgb(0 0 0 / 0%) 94%);
    height: 99px;
    width: 100%;
    font-family: "YouTube Noto",Roboto,Arial,Helvetica,sans-serif;
    color: hsl(0deg 0% 93.33%);
    text-shadow: 0 0 2px rgba(0,0,0,.5);
    font-size: 18px;
    padding: 25px 20px;
    overflow: hidden;
    white-space: nowrap;
    text-overflow: ellipsis;
    box-sizing: border-box;
}

lite-youtube:hover::before {
    color: white;
}

/* responsive iframe with a 16:9 aspect ratio
    thanks https://css-tricks.com/responsive-iframes/
*/
lite-youtube::after {
    content: "";
    display: block;
    padding-bottom: calc(100% / (16 / 9));
}
lite-youtube > iframe {
    width: 100%;
    height: 100%;
    position: absolute;
    top: 0;
    left: 0;
    border: 0;
}

/* play button */
lite-youtube > .lty-playbtn {
    display: block;
    /* Make the button element cover the whole area for a large hover/click target… */
    width: 100%;
    height: 100%;
    /* …but visually it's still the same size */
    background: no-repeat center/68px 48px;
    /* YT's actual play button svg */
    background-image: url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 68 48"><path d="M66.52 7.74c-.78-2.93-2.49-5.41-5.42-6.19C55.79.13 34 0 34 0S12.21.13 6.9 1.55c-2.93.78-4.63 3.26-5.42 6.19C.06 13.05 0 24 0 24s.06 10.95 1.48 16.26c.78 2.93 2.49 5.41 5.42 6.19C12.21 47.87 34 48 34 48s21.79-.13 27.1-1.55c2.93-.78 4.64-3.26 5.42-6.19C67.94 34.95 68 24 68 24s-.06-10.95-1.48-16.26z" fill="red"/><path d="M45 24 27 14v20" fill="white"/></svg>');
    position: absolute;
    cursor: pointer;
    z-index: 1;
    filter: grayscale(100%);
    transition: filter .1s cubic-bezier(0, 0, 0.2, 1);
    border: 0;
}

lite-youtube:hover > .lty-playbtn,
lite-youtube .lty-playbtn:focus {
    filter: none;
}

/* Post-click styles */
lite-youtube.lyt-activated {
    cursor: unset;
}
lite-youtube.lyt-activated::before,
lite-youtube.lyt-activated > .lty-playbtn {
    opacity: 0;
    pointer-events: none;
}

.lyt-visually-hidden {
    clip: rect(0 0 0 0);
    clip-path: inset(50%);
    height: 1px;
    overflow: hidden;
    position: absolute;
    white-space: nowrap;
    width: 1px;
  }
		</style>
	</head>

	<body style="--nav-item-active: 1;">
		<div class="noise-container"></div>
		<a href="#skip" class="visually-hidden">Skip to main content</a>
		<div class="layout-wrapper">
			<header class="site-header">
				<nav>
					<h2 class="visually-hidden">Top level navigation menu</h2>
					<div class="nav-bubble">
    <button id="chat-reset" class="chat-reset" aria-label="Reset chat">↺</button>
    <div id="navPhrase" class="nav-phrase">
        
            
            <a href="/" style="text-decoration: none;">Home</a>&emsp;<a href="/projects/" style="text-decoration: none;">Projects</a>&emsp;<a href="/blog/" style="text-decoration: none;">Blog</a>&emsp;<a href="/about/" style="text-decoration: none;">About Me</a>
        
    </div>
    <form method="post" id="theme-form" class="theme-toggle">
        <input type="checkbox" id="dark-mode-toggle" name="theme" value="dark" aria-label="Toggle dark mode">
        <label for="dark-mode-toggle"></label>
    </form>
</div>
					<div class="side-nav">
						<ul class="nav-list">
							<li id="chat-toggle" class="nav-item">Welcome!</li>
								<li class="nav-item">
									<a href="/">Home</a>
								</li>
								<li class="nav-item">
									<a href="/projects/">Projects</a>
								</li>
								<li class="nav-item">
									<a href="/blog/">Blog</a>
								</li>
								<li class="nav-item">
									<a href="/about/">About Me</a>
								</li>
						</ul>
					</div>
				</nav>

				
			</header>

			<main id="skip">
				
<div class="progress-bar"></div>

<article class="post">
  
  <h1 id="post-title" data-emoji="🌎">
    Soniweb: An Experiment in Web Traffic Sonification and Ambisonics&ensp;🌎
  </h1>

  <ul class="post-metadata">
    <li>
      <time datetime="2020-03-09">09 March 2020</time>
    </li>
      <li>
        <a href="/tags/projects/" class="post-tag">projects</a>
      </li>
  </ul>

  <h1 id="sonification-of-the-net" tabindex="-1">Sonification of the Net <a class="header-anchor" href="#sonification-of-the-net">#</a></h1>
<p>For the MCT's sonification course, our group developed a system that collects and geo-locates web requests in real-time <em>and</em> <a href="https://en.wikipedia.org/wiki/Sonification">sonified</a> this incoming data. We were inspired by the paper and project <a href="https://www.researchgate.net/publication/334041357_Surfing_In_Sound_Sonification_of_Hidden_Web_Tracking">Surfing in Sound</a> which sonifies web-trackers via Ableton with an emphasis on user awareness and with potential of extending the experience into an audio-visual installation. A demo of their system can be viewed <a href="https://www.youtube.com/watch?v=ug3GfEe801k">here</a>. Another project with similar aims, <a href="https://www.researchgate.net/publication/335452963_Soundbeam_a_Platform_for_Sonifying_Web_Tracking">Soundbeam</a>, sonifies various trackers through SuperCollider while visiting a web-page as a lens into internet privacy. Our project, Soniweb, finds closer alignment with Surfing in Sound, employing a combination of Wireshark, Python, and Pure Data.</p>
<p>Our initial plan was to filter network traffic exclusively from the web browser and then analyze the HTTP response headers for information regarding the resources that are loaded when one visits a webpage. From there, we would send that data over OSC to Pure Data, a visual audio programming language and generate sound from it. However, we found (after extensive testing with various programs) that https webpages encrypt the view of the pages' resources (the s stands for the SSL protocol) - this should have been more obvious at the beginning. This prevents a 3rd party application like <a href="https://www.wireshark.org/">Wireshark</a> from spying in on the network activity and reading the data that is transferred. While this is a wonderful standard for the sake of security, it prevented us from going in that direction as Wireshark is unable to decrypt SSL layers. Another application, <a href="https://www.telerik.com/fiddler">Fiddler</a>, an alternative to Wireshark, is able to achieve this, however, its implementation has poor integration with Python and even less on macOS. So our vision broadened to include all possible network activity that is transmitted on a computer and we went with Wireshark as a tried and true stable of the data-sniffing community.</p>
<h2 id="implementation" tabindex="-1">Implementation <a class="header-anchor" href="#implementation">#</a></h2>
<p>We decided early on that it would be quite interesting if we were able to sonify the locations of the data packets that were being sent and received when one uses the computer. From a research oriented position, the sonification and spatialization of web data might provide the computer user with insights into:</p>
<ol>
<li>Where the data you see, while casually browsing the web or using a web-dependent application, actually originates from (<strong>digital-physical correspondence &amp; global network monopolies</strong>)</li>
<li>How one's device is constantly sending and receiving information, even in a seemingly inactive state (<strong>the inextricable internet</strong>) and in contrast...</li>
<li>How some webpages and applications take much more aggressive approaches in making contact with your device (<strong>web tracking &amp; privacy overreach</strong>)</li>
</ol>
<p>These guided our development and led us to tailor the data manipulation towards a sonified experience that could encompass these ideas. This led us to look for databases that would provide a massive list of IP’s with associated geodata (country, city and IP address). We ended up with one of <a href="https://dev.maxmind.com/geoip/geoip2/downloadable/">Geoip2’s</a> free databases, which appeared to be the most comprehensive, free collection of IP-to-coordinate entries available for this task. With their accompanying python package, we were able to import the database quite easily and look up the source and destination IP addresses of every packet that passed through our Wireshark server (tshark) that would be hosted in Python.</p>
<p>Half of us were first tasked with the development of the network sniffing script in Python. This involved working with a Wireshark wrapper for Python called <a href="https://github.com/KimiNewt/pyshark">pyshark</a> which allows us to host a Wireshark instance and read and filter packet data completely within Python.</p>
<pre class="language-python" tabindex="0"><code class="language-python"><span class="token comment"># Set up capture and filter by host IP and packet size</span>
capture <span class="token operator">=</span> pyshark<span class="token punctuation">.</span>LiveCapture<span class="token punctuation">(</span>interface<span class="token operator">=</span><span class="token string">"en0"</span><span class="token punctuation">,</span>
                              bpf_filter<span class="token operator">=</span><span class="token string">"host "</span><span class="token operator">+</span>host_ip<span class="token operator">+</span>
                              <span class="token string">"&amp;&amp; length > 60"</span><span class="token punctuation">)</span></code></pre>
<p>This snippet of code constructed the capture stream and specified the network we were listening to (the Wi-Fi), which IP addresses we wanted to filter into our stream (our machine's host IP), and what size we wanted the packets to be (this was to reduce the torrents of data that may be less relevant to our network activity).</p>
<p>There wasn't too much documentation on pyshark’s full capabilities, so we spent a good portion of time getting familiar with the package as well as Wireshark, which the package relied upon. Once we had exhausted the aforementioned possibility of getting metadata from webpages, we began to program a simple packet to OSC script that would send OSC messages to <a href="https://puredata.info/">Pure Data</a> (Pd) when a packet was sent or received into the computer. We would have a Pd patch running simultaneously to the Python script to listen to our OSC messages with the port specified. Here's the code that does this below</p>
<pre class="language-python" tabindex="0"><code class="language-python"><span class="token comment"># Set up OSC server</span>
parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--ip"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">"127.0.0.1"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--port"</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">8888</span><span class="token punctuation">)</span>
args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>
client <span class="token operator">=</span> udp_client<span class="token punctuation">.</span>SimpleUDPClient<span class="token punctuation">(</span>args<span class="token punctuation">.</span>ip<span class="token punctuation">,</span> args<span class="token punctuation">.</span>port<span class="token punctuation">)</span></code></pre>
<p>Further development included generating longitude and latitude from the IP addresses and transforming them into ranges that we could eventually use in the Pd patch. We ended up splitting longitudinal values across 8 positions and 4 positions for latitude. This was a compromise due to the computational expense involved using 32 channels from which we would play multiple samples. Because we filtered in packets that either contained our host IP (the IP of the computer running the script) as the source IP or destination IP, we were able to send a single latitude and longitude pair along with a message giving the direction (sent or received). The protocol of the packet (TCP, UDP, TLS, DNS, other) and its length (or size) was also sent as OSC messages.</p>
<pre class="language-python" tabindex="0"><code class="language-python"><span class="token comment"># Sent</span>
<span class="token keyword">if</span> packet<span class="token punctuation">.</span>ip<span class="token punctuation">.</span>src <span class="token operator">==</span> host_ip<span class="token punctuation">:</span>
    dst_resp <span class="token operator">=</span> reader<span class="token punctuation">.</span>city<span class="token punctuation">(</span>packet<span class="token punctuation">.</span>ip<span class="token punctuation">.</span>dst<span class="token punctuation">)</span>
    client<span class="token punctuation">.</span>send_message<span class="token punctuation">(</span><span class="token string">"/dest_name"</span><span class="token punctuation">,</span> dst_resp<span class="token punctuation">.</span>country<span class="token punctuation">.</span>name<span class="token punctuation">)</span>
    client<span class="token punctuation">.</span>send_message<span class="token punctuation">(</span><span class="token string">"/direction"</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
    client<span class="token punctuation">.</span>send_message<span class="token punctuation">(</span><span class="token string">"/ip_lat"</span><span class="token punctuation">,</span>
                        <span class="token builtin">round</span><span class="token punctuation">(</span><span class="token punctuation">(</span>dst_resp<span class="token punctuation">.</span>location<span class="token punctuation">.</span>latitude<span class="token operator">+</span><span class="token number">90</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">60</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                        <span class="token comment"># 0 to 3 (4 degrees of differentiation)</span>
    client<span class="token punctuation">.</span>send_message<span class="token punctuation">(</span><span class="token string">"/ip_long"</span><span class="token punctuation">,</span>
                        <span class="token builtin">round</span><span class="token punctuation">(</span><span class="token punctuation">(</span>dst_resp<span class="token punctuation">.</span>location<span class="token punctuation">.</span>longitude<span class="token operator">+</span><span class="token number">180</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">51.43</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                        <span class="token comment"># 0 to 7 (8 degrees of differentiation)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Sent to "</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>dst_resp<span class="token punctuation">.</span>country<span class="token punctuation">.</span>name<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<h2 id="sonification" tabindex="-1">Sonification <a class="header-anchor" href="#sonification">#</a></h2>
<p>All the while, our third group member started development on the Pure Data patch simultaneous to our work in Python. He began with a sample handler that would play five different samples that corresponded to the protocol type, amplitude. We initially attempted ambisonics production through <a href="https://www.reaper.fm/">Reaper</a> as a DAW but found a wonderful (and actively developed updated) library for Pd called <a href="https://github.com/Spacechild1/vstplugin">vstplugin~</a> where we loaded the <a href="https://plugins.iem.at/">IEM</a> plugin suite for ambisonics. The library worked quite well for our purposes and we were able to load each of our 32 channel’s azimuth and elevations as an initialization process. Each of the “voice” sub-patches contain five “samplehandler” sub-patches to play any of the potential five sounds given the protocol message. Within these sub-patches is one “singlesample” sub-patch that plays the sample with “tabread4~”. However, this sub-patch is cloned for times for the possibility of a single channel playing a particular sample up to four times simultaneously. This was built in due to the high frequency of packet data that we receive during the python script’s playback.</p>
<figure><img src="/img/soniweb-pd.png" alt="The Pure Data patch (and sub-patches)" loading="lazy" decoding="async" /><figcaption>The Pure Data patch (and sub-patches)</figcaption></figure>
<h2 id="the-effect" tabindex="-1">The Effect <a class="header-anchor" href="#the-effect">#</a></h2>
<p>When running the script and patch simultaneously, the network activity that your current machine is relaying is sonified and located in a <a href="https://en.wikipedia.org/wiki/Ambisonics">5th order ambisonics</a> environment. The various bells ping around the listener as if they were sitting in the center of the Earth listening to the machines around them speak to one another. While we achieved our set goals, there are a few unanswered questions as to whether the packets that are being received are actually too quick to receive and process in real-time and may become backlogged over the course of a session. This may either have to do with limitations imposed by Pd, Python, Wireshark or the CPU power afforded by the user’s computer. In a recent update, converting one of the &quot;if&quot; statements to a dpf filter within pyshark's instantiation made the incoming packets quite responsive to web browsing activity. However, it may be possible to mitigate these issues and enhance the sonification by generating the instruments within Pd rather than using sample files. This project has great potential for an extension into a live installation, one, perhaps, that asks the audience to connect their devices to a network hosted in the space so that they could listen to the network activity of their collective devices.</p>
<figure><video src="https://www.uio.no/english/studies/programmes/mct-master/blog/assets/video/2020_03_07_jacksong_soniweb_demo.mp4" style="aspect-ratio: 16/9;" controls>Your browser does not support the video tag.</video><figcaption>A demo of Soniweb (headphones required!)</figcaption></figure>
<h2 id="works-cited" tabindex="-1">Works Cited <a class="header-anchor" href="#works-cited">#</a></h2>
<p class="citation">Telerik. (2020). <em>Fiddler - Free Web Debugging Proxy</em>. Retrieved from <a href="https://www.telerik.com/fiddler">https://www.telerik.com/fiddler</a></p>
<p class="citation">Hutchins, Charles, et al.. (2014). <em>Soundbeam: A Platform for Sonifying Web Tracking</em></p>
<p class="citation">MaxMind. (2020). <em>GeoIP2 Downloadable Databases</em>. Retrieved from <a href="https://dev.maxmind.com/geoip/geoip2/downloadable/">https://dev.maxmind.com/geoip/geoip2/downloadable/</a></p>
<p class="citation">Green, Dor. (2020). <em>KimiNewt/Pyshark</em>. Retrieved from <a href="https://github.com/KimiNewt/pyshark">https://github.com/KimiNewt/pyshark</a></p>
<p class="citation">Lutz, Otto, et al.. (2019). <em>Surfing In Sound: Sonification of Hidden Web Tracking</em>. Retrieved from <a href="https://doi.org/10.21785/icad2019.071">https://doi.org/10.21785/icad2019.071</a></p>
<p class="citation">Pure Data. (2020). <em>Pd Community Site</em>. Retrieved from <a href="https://puredata.info/">https://puredata.info/</a></p>
<p class="citation">REAPER. (2020). <em>Audio Production Without Limits</em>. Retrieved from <a href="https://www.reaper.fm/">https://www.reaper.fm/</a></p>
<p class="citation">Ressi, Christof. (2020). <em>Spacechild1/Vstplugin</em>. Retrieved from <a href="https://github.com/Spacechild1/vstplugin">https://github.com/Spacechild1/vstplugin</a></p>
<p class="citation">Rudrich, Daniel. (2020). <em>IEM Plug-in Suite</em>. Retrieved from <a href="https://plugins.iem.at/">https://plugins.iem.at/</a></p>
<p class="citation">Wireshark. (2020). <em>Go Deep</em>. Retrieved from <a href="https://www.wireshark.org/">https://www.wireshark.org/</a></p>

      <ul class="links-nextprev">
          <li>Previous: <a href="/projects/2020-02-10-osc-guitar/">Strumming through space and OSC</a>
          </li>
        
          <li>Next: <a href="/projects/2020-04-08-soniweb-2/">Soniweb: Epilogue</a>
          </li>
        
      </ul>
</article>

<script src="/js/emoji-color.js"></script>
			</main>
		</div>
		<footer></footer>

		<!-- This page `/projects/2020-03-09-soniweb/` was built on 2024-09-11T00:04:49.904Z -->
	</body>
</html>
<script defer>
	// Minimal JS for handling user preference
(function () {
    const toggle = document.getElementById('dark-mode-toggle');

    // Set initial state based on localStorage or system preference
    const storedTheme = localStorage.getItem('color-scheme');
    if (storedTheme) {
        document.documentElement.setAttribute('data-theme', storedTheme);
        toggle.checked = storedTheme === 'dark';
    }

    // Handle toggle changes
    toggle.addEventListener('change', () => {
        const newTheme = toggle.checked ? 'dark' : 'light';
        document.documentElement.setAttribute('data-theme', newTheme);
        localStorage.setItem('color-scheme', newTheme);
    });

    // const form = document.getElementById('theme-form');
    // Handle form submission (for no-JS fallback)
    // form.addEventListener('submit', (e) => {
    //     e.preventDefault();
    //     const formData = new FormData(form);
    //     fetch('/set-theme', {
    //         method: 'POST',
    //         body: formData
    //     }).then(() => {
    //         location.reload();
    //     });
    // });
})();

		// Generate a random user ID if not already stored
function getUserId() {
	let userId = localStorage.getItem("userId");
	if (!userId) {
		userId = "user_" + Math.random().toString(36).slice(2, 11);
		localStorage.setItem("userId", userId);
	}
	return userId;
}

function sendMessageToWorker(message) {
	const isDevelopment =
		window.location.hostname === "localhost" ||
		window.location.hostname === "127.0.0.1";
	const baseUrl = isDevelopment ? "http://localhost:8090" : "";

	const isDarkMode =
		document.documentElement.getAttribute("data-theme") === "dark";
	const animalParam = isDarkMode ? "frog" : "chicken";
	const waitText = isDarkMode ? "Ribbit" : "Cluck";

	updateNavPhrase(waitText, true);

	const userId = getUserId();

	fetch(
		`${baseUrl}/ai?message=${encodeURIComponent(message)}&animal=${animalParam}&userId=${userId}`,
	)
		.then((response) => response.json())
		.then((data) => {
			updateNavPhrase(data.response || `Error: ${data.error}`);
		})
		.catch((error) => {
			console.error("Fetch error:", error);
			updateNavPhrase("Sorry, something went wrong.");
		});
}

function updateNavPhrase(text, isWaiting = false) {
	const navPhrase = document.getElementById("navPhrase");
	navPhrase.textContent = text;
	navPhrase.classList.toggle("waiting", isWaiting);

	// Add this line to make the chat bubble clickable again after receiving a response
	if (!isWaiting) {
		navPhrase.classList.add("clickable");
	}
}

document.addEventListener("DOMContentLoaded", function () {
	const chatTrigger = document.getElementById("chat-toggle");
	const talkBubble = document.querySelector(".nav-bubble");
	const mainContent = document.querySelector("main");
	const navPhrase = document.getElementById("navPhrase");
	let originalContent = navPhrase.innerHTML;

	const chatReset = document.getElementById("chat-reset");

	function resetChatInterface() {
		navPhrase.innerHTML = originalContent;
		talkBubble.classList.remove("chat-active");
		mainContent.classList.remove("chat-active");
	}

	chatReset.addEventListener("click", resetChatInterface);

	function activateChatInterface() {
		navPhrase.innerHTML = `
			<form id="chat-form">
				<input type="text" id="user-input" placeholder="Search... or say hi?">
				<button type="submit" style="display:none;">Send</button>
			</form>
			<div id="search-results"></div>
		`;
		const userInput = document.getElementById("user-input");
		userInput.focus();

		const searchResults = document.getElementById("search-results");
		let pagefind;

		userInput.addEventListener("input", async function () {
			if (!pagefind) {
				pagefind = await import("/pagefind/pagefind.js");
				await pagefind.options({
					element: "#search-results",
					excerptLength: 15,
					highlightParam: "highlight",
				});
				await pagefind.init();
			}

			const query = userInput.value.trim();
			if (query.length > 2) {
				const search = await pagefind.search(query);
				const results = await Promise.all(search.results.map((r) => r.data()));

				if (results.length > 0) {
					searchResults.innerHTML = results
						.map(
							(result) => `
							<a href="${result.url}" class="search-result">
								<div class="search-result-title">${result.meta.title || "Untitled"}</div>
								<p>${result.excerpt}</p>
							</a>
						`,
						)
						.join("");
					talkBubble.classList.add("chat-active");
				} else {
					searchResults.innerHTML = "";
				}
			} else {
				searchResults.innerHTML = "";
			}
		});

		document
			.getElementById("chat-form")
			.addEventListener("submit", function (e) {
				e.preventDefault();
				if (userInput.value.trim() !== "") {
					sendMessageToWorker(userInput.value.trim());
					userInput.value = "";
					searchResults.innerHTML = "";
				}
			});

		// Add event listener for escape key to reset chat interface
		userInput.addEventListener("keydown", function (e) {
			if (e.key === "Escape") {
				resetChatInterface();
			}
		});
	}

	function handleChatTrigger() {
		talkBubble.classList.toggle("chat-active");
		mainContent.classList.toggle("chat-active");

		if (talkBubble.classList.contains("chat-active")) {
			activateChatInterface();
		} else {
			navPhrase.innerHTML = originalContent;
		}
	}

	chatTrigger.addEventListener("click", handleChatTrigger);

	// Modify this event listener to handle clicks on the chat bubble
	navPhrase.addEventListener("click", function (event) {
		// Check if the clicked element is a link
		if (event.target.tagName.toLowerCase() === "a") {
			// If it's a link, let the default action happen (follow the link)
			return;
		}

		if (
			window.innerWidth < 840 &&
			!talkBubble.classList.contains("chat-active")
		) {
			handleChatTrigger();
		} else if (navPhrase.classList.contains("clickable")) {
			activateChatInterface();
			navPhrase.classList.remove("clickable");
		}
	});
});


		
			
			/**
 * A lightweight youtube embed. Still should feel the same to the user, just MUCH faster to initialize and paint.
 *
 * Thx to these as the inspiration
 *   https://storage.googleapis.com/amp-vs-non-amp/youtube-lazy.html
 *   https://autoplay-youtube-player.glitch.me/
 *
 * Once built it, I also found these:
 *   https://github.com/ampproject/amphtml/blob/master/extensions/amp-youtube (👍👍)
 *   https://github.com/Daugilas/lazyYT
 *   https://github.com/vb/lazyframe
 */
class LiteYTEmbed extends HTMLElement {
    connectedCallback() {
        this.videoId = this.getAttribute('videoid');

        let playBtnEl = this.querySelector('.lty-playbtn');
        // A label for the button takes priority over a [playlabel] attribute on the custom-element
        this.playLabel = (playBtnEl && playBtnEl.textContent.trim()) || this.getAttribute('playlabel') || 'Play';

        this.dataset.title = this.getAttribute('title') || "";

        /**
         * Lo, the youtube poster image!  (aka the thumbnail, image placeholder, etc)
         *
         * See https://github.com/paulirish/lite-youtube-embed/blob/master/youtube-thumbnail-urls.md
         */
        if (!this.style.backgroundImage) {
          this.style.backgroundImage = `url("https://i.ytimg.com/vi/${this.videoId}/hqdefault.jpg")`;
          this.upgradePosterImage();
        }

        // Set up play button, and its visually hidden label
        if (!playBtnEl) {
            playBtnEl = document.createElement('button');
            playBtnEl.type = 'button';
            playBtnEl.classList.add('lty-playbtn');
            this.append(playBtnEl);
        }
        if (!playBtnEl.textContent) {
            const playBtnLabelEl = document.createElement('span');
            playBtnLabelEl.className = 'lyt-visually-hidden';
            playBtnLabelEl.textContent = this.playLabel;
            playBtnEl.append(playBtnLabelEl);
        }

        this.addNoscriptIframe();

        // for the PE pattern, change anchor's semantics to button
        if(playBtnEl.nodeName === 'A'){
            playBtnEl.removeAttribute('href');
            playBtnEl.setAttribute('tabindex', '0');
            playBtnEl.setAttribute('role', 'button');
            // fake button needs keyboard help
            playBtnEl.addEventListener('keydown', e => {
                if( e.key === 'Enter' || e.key === ' ' ){
                    e.preventDefault();
                    this.activate();
                }
            });
        }

        // On hover (or tap), warm up the TCP connections we're (likely) about to use.
        this.addEventListener('pointerover', LiteYTEmbed.warmConnections, {once: true});
        this.addEventListener('focusin', LiteYTEmbed.warmConnections, {once: true});

        // Once the user clicks, add the real iframe and drop our play button
        // TODO: In the future we could be like amp-youtube and silently swap in the iframe during idle time
        //   We'd want to only do this for in-viewport or near-viewport ones: https://github.com/ampproject/amphtml/pull/5003
        this.addEventListener('click', this.activate);

        // Chrome & Edge desktop have no problem with the basic YouTube Embed with ?autoplay=1
        // However Safari desktop and most/all mobile browsers do not successfully track the user gesture of clicking through the creation/loading of the iframe,
        // so they don't autoplay automatically. Instead we must load an additional 2 sequential JS files (1KB + 165KB) (un-br) for the YT Player API
        // TODO: Try loading the the YT API in parallel with our iframe and then attaching/playing it. #82
        this.needsYTApi = this.hasAttribute("js-api") || navigator.vendor.includes('Apple') || navigator.userAgent.includes('Mobi');
    }

    /**
     * Add a <link rel={preload | preconnect} ...> to the head
     */
    static addPrefetch(kind, url, as) {
        const linkEl = document.createElement('link');
        linkEl.rel = kind;
        linkEl.href = url;
        if (as) {
            linkEl.as = as;
        }
        document.head.append(linkEl);
    }

    /**
     * Begin pre-connecting to warm up the iframe load
     * Since the embed's network requests load within its iframe,
     *   preload/prefetch'ing them outside the iframe will only cause double-downloads.
     * So, the best we can do is warm up a few connections to origins that are in the critical path.
     *
     * Maybe `<link rel=preload as=document>` would work, but it's unsupported: http://crbug.com/593267
     * But TBH, I don't think it'll happen soon with Site Isolation and split caches adding serious complexity.
     */
    static warmConnections() {
        if (LiteYTEmbed.preconnected) return;

        // The iframe document and most of its subresources come right off youtube.com
        LiteYTEmbed.addPrefetch('preconnect', 'https://www.youtube-nocookie.com');
        // The botguard script is fetched off from google.com
        LiteYTEmbed.addPrefetch('preconnect', 'https://www.google.com');

        // Not certain if these ad related domains are in the critical path. Could verify with domain-specific throttling.
        LiteYTEmbed.addPrefetch('preconnect', 'https://googleads.g.doubleclick.net');
        LiteYTEmbed.addPrefetch('preconnect', 'https://static.doubleclick.net');

        LiteYTEmbed.preconnected = true;
    }

    fetchYTPlayerApi() {
        if (window.YT || (window.YT && window.YT.Player)) return;

        this.ytApiPromise = new Promise((res, rej) => {
            var el = document.createElement('script');
            el.src = 'https://www.youtube.com/iframe_api';
            el.async = true;
            el.onload = _ => {
                YT.ready(res);
            };
            el.onerror = rej;
            this.append(el);
        });
    }

    /** Return the YT Player API instance. (Public L-YT-E API) */
    async getYTPlayer() {
        if(!this.playerPromise) {
            await this.activate();
        }

        return this.playerPromise;
    }

    async addYTPlayerIframe() {
        this.fetchYTPlayerApi();
        await this.ytApiPromise;

        const videoPlaceholderEl = document.createElement('div')
        this.append(videoPlaceholderEl);

        const paramsObj = Object.fromEntries(this.getParams().entries());

        this.playerPromise = new Promise(resolve => {
            let player = new YT.Player(videoPlaceholderEl, {
                width: '100%',
                videoId: this.videoId,
                playerVars: paramsObj,
                events: {
                    'onReady': event => {
                        event.target.playVideo();
                        resolve(player);
                    }
                }
            });
        });
    }

    // Add the iframe within <noscript> for indexability discoverability. See https://github.com/paulirish/lite-youtube-embed/issues/105
    addNoscriptIframe() {
        const iframeEl = this.createBasicIframe();
        const noscriptEl = document.createElement('noscript');
        // Appending into noscript isn't equivalant for mysterious reasons: https://html.spec.whatwg.org/multipage/scripting.html#the-noscript-element
        noscriptEl.innerHTML = iframeEl.outerHTML;
        this.append(noscriptEl);
    }

    getParams() {
        const params = new URLSearchParams(this.getAttribute('params') || []);
        params.append('autoplay', '1');
        params.append('playsinline', '1');
        return params;
    }

    async activate(){
        if (this.classList.contains('lyt-activated')) return;
        this.classList.add('lyt-activated');

        if (this.needsYTApi) {
            return this.addYTPlayerIframe(this.getParams());
        }

        const iframeEl = this.createBasicIframe();
        this.append(iframeEl);

        // Set focus for a11y
        iframeEl.focus();
    }

    createBasicIframe(){
        const iframeEl = document.createElement('iframe');
        iframeEl.width = 560;
        iframeEl.height = 315;
        // No encoding necessary as [title] is safe. https://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#:~:text=Safe%20HTML%20Attributes%20include
        iframeEl.title = this.playLabel;
        iframeEl.allow = 'accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture';
        iframeEl.allowFullscreen = true;
        // AFAIK, the encoding here isn't necessary for XSS, but we'll do it only because this is a URL
        // https://stackoverflow.com/q/64959723/89484
        iframeEl.src = `https://www.youtube-nocookie.com/embed/${encodeURIComponent(this.videoId)}?${this.getParams().toString()}`;
        return iframeEl;
    }

    /**
     * In the spirit of the `lowsrc` attribute and progressive JPEGs, we'll upgrade the reliable
     * poster image to a higher resolution one, if it's available.
     * Interestingly this sddefault webp is often smaller in filesize, but we will still attempt it second
     * because getting _an_ image in front of the user if our first priority.
     *
     * See https://github.com/paulirish/lite-youtube-embed/blob/master/youtube-thumbnail-urls.md for more details
     */
    upgradePosterImage() {
         // Defer to reduce network contention.
        setTimeout(() => {
            const webpUrl = `https://i.ytimg.com/vi_webp/${this.videoId}/sddefault.webp`;
            const img = new Image();
            img.fetchPriority = 'low'; // low priority to reduce network contention
            img.referrerpolicy = 'origin'; // Not 100% sure it's needed, but https://github.com/ampproject/amphtml/pull/3940
            img.src = webpUrl;
            img.onload = e => {
                // A pretty ugly hack since onerror won't fire on YouTube image 404. This is (probably) due to
                // Youtube's style of returning data even with a 404 status. That data is a 120x90 placeholder image.
                // … per "annoying yt 404 behavior" in the .md
                const noAvailablePoster = e.target.naturalHeight == 90 && e.target.naturalWidth == 120;
                if (noAvailablePoster) return;

                this.style.backgroundImage = `url("${webpUrl}")`;
            }
        }, 100);
    }
}
// Register custom element
customElements.define('lite-youtube', LiteYTEmbed);

			const style = document.head.appendChild(document.createElement('style'));
style.textContent = /*css*/`

  lite-vimeo {
    aspect-ratio: 16 / 9;
    background-color: #000;
    position: relative;
    display: block;
    contain: content;
    background-position: center center;
    background-size: cover;
    cursor: pointer;
  }

  lite-vimeo > iframe {
    width: 100%;
    height: 100%;
    position: absolute;
    top: 0;
    left: 0;
    border: 0;
  }

  lite-vimeo > .ltv-playbtn {
    font-size: 10px;
    padding: 0;
    width: 6.5em;
    height: 4em;
    background: rgba(23, 35, 34, .75);
    z-index: 1;
    opacity: .8;
    border-radius: .5em;
    transition: opacity .2s ease-out, background .2s ease-out;
    outline: 0;
    border: 0;
    cursor: pointer;
  }

  lite-vimeo:hover > .ltv-playbtn {
    background-color: rgb(0, 173, 239);
    opacity: 1;
  }

  /* play button triangle */
  lite-vimeo > .ltv-playbtn::before {
    content: '';
    border-style: solid;
    border-width: 10px 0 10px 20px;
    border-color: transparent transparent transparent #fff;
  }

  lite-vimeo > .ltv-playbtn,
  lite-vimeo > .ltv-playbtn::before {
    position: absolute;
    top: 50%;
    left: 50%;
    transform: translate3d(-50%, -50%, 0);
  }

  /* Post-click styles */
  lite-vimeo.ltv-activated {
    cursor: unset;
  }

  lite-vimeo.ltv-activated::before,
  lite-vimeo.ltv-activated > .ltv-playbtn {
    opacity: 0;
    pointer-events: none;
  }
`;

/**
 * Ported from https://github.com/paulirish/lite-youtube-embed
 *
 * A lightweight vimeo embed. Still should feel the same to the user, just MUCH faster to initialize and paint.
 *
 * Thx to these as the inspiration
 *   https://storage.googleapis.com/amp-vs-non-amp/youtube-lazy.html
 *   https://autoplay-youtube-player.glitch.me/
 *
 * Once built it, I also found these:
 *   https://github.com/ampproject/amphtml/blob/master/extensions/amp-youtube (👍👍)
 *   https://github.com/Daugilas/lazyYT
 *   https://github.com/vb/lazyframe
 */
class LiteVimeo extends (globalThis.HTMLElement ?? class {}) {
  /**
   * Begin pre-connecting to warm up the iframe load
   * Since the embed's network requests load within its iframe,
   *   preload/prefetch'ing them outside the iframe will only cause double-downloads.
   * So, the best we can do is warm up a few connections to origins that are in the critical path.
   *
   * Maybe `<link rel=preload as=document>` would work, but it's unsupported: http://crbug.com/593267
   * But TBH, I don't think it'll happen soon with Site Isolation and split caches adding serious complexity.
   */
  static _warmConnections() {
    if (LiteVimeo.preconnected) return;
    LiteVimeo.preconnected = true;

    // The iframe document and most of its subresources come right off player.vimeo.com
    addPrefetch('preconnect', 'https://player.vimeo.com');
    // Images
    addPrefetch('preconnect', 'https://i.vimeocdn.com');
    // Files .js, .css
    addPrefetch('preconnect', 'https://f.vimeocdn.com');
    // Metrics
    addPrefetch('preconnect', 'https://fresnel.vimeocdn.com');
  }

  connectedCallback() {
    this.videoId = this.getAttribute('videoid');

    /**
     * Lo, the vimeo placeholder image!  (aka the thumbnail, poster image, etc)
     * We have to use the Vimeo API.
     */
    let { width, height } = getThumbnailDimensions(this.getBoundingClientRect());
    let devicePixelRatio = window.devicePixelRatio || 1;
    if (devicePixelRatio >= 2) devicePixelRatio *= .75;
    width = Math.round(width * devicePixelRatio);
    height = Math.round(height * devicePixelRatio);

    fetch(`https://vimeo.com/api/v2/video/${this.videoId}.json`)
      .then(response => response.json())
      .then(data => {
        let thumbnailUrl = data[0].thumbnail_large;
        thumbnailUrl = thumbnailUrl.replace(/-d_[\dx]+$/i, `-d_${width}x${height}`);
        this.style.backgroundImage = `url("${thumbnailUrl}")`;
      });

    let playBtnEl = this.querySelector('.ltv-playbtn');
    // A label for the button takes priority over a [playlabel] attribute on the custom-element
    this.playLabel = (playBtnEl && playBtnEl.textContent.trim()) || this.getAttribute('playlabel') || 'Play video';

    if (!playBtnEl) {
      playBtnEl = document.createElement('button');
      playBtnEl.type = 'button';
      playBtnEl.setAttribute('aria-label', this.playLabel);
      playBtnEl.classList.add('ltv-playbtn');
      this.append(playBtnEl);
    }
    playBtnEl.removeAttribute('href');

    // On hover (or tap), warm up the TCP connections we're (likely) about to use.
    this.addEventListener('pointerover', LiteVimeo._warmConnections, {
      once: true
    });

    // Once the user clicks, add the real iframe and drop our play button
    // TODO: In the future we could be like amp-youtube and silently swap in the iframe during idle time
    //   We'd want to only do this for in-viewport or near-viewport ones: https://github.com/ampproject/amphtml/pull/5003
    this.addEventListener('click', this.addIframe);
  }

  addIframe() {
    if (this.classList.contains('ltv-activated')) return;
    this.classList.add('ltv-activated');

    const iframeEl = document.createElement('iframe');
    iframeEl.width = 640;
    iframeEl.height = 360;
    // No encoding necessary as [title] is safe. https://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#:~:text=Safe%20HTML%20Attributes%20include
    iframeEl.title = this.playLabel;
    iframeEl.allow = 'accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture';
    // AFAIK, the encoding here isn't necessary for XSS, but we'll do it only because this is a URL
    // https://stackoverflow.com/q/64959723/89484
    iframeEl.src = `https://player.vimeo.com/video/${encodeURIComponent(this.videoId)}?autoplay=1`;
    this.append(iframeEl);

    // Set focus for a11y
    iframeEl.addEventListener('load', iframeEl.focus, { once: true });
  }
}

if (globalThis.customElements && !globalThis.customElements.get('lite-vimeo')) {
  globalThis.customElements.define('lite-vimeo', LiteVimeo);
}

/**
 * Add a <link rel={preload | preconnect} ...> to the head
 */
function addPrefetch(kind, url, as) {
  const linkElem = document.createElement('link');
  linkElem.rel = kind;
  linkElem.href = url;
  if (as) {
    linkElem.as = as;
  }
  linkElem.crossorigin = true;
  document.head.append(linkElem);
}

/**
 * Get the thumbnail dimensions to use for a given player size.
 *
 * @param {Object} options
 * @param {number} options.width The width of the player
 * @param {number} options.height The height of the player
 * @return {Object} The width and height
 */
function getThumbnailDimensions({ width, height }) {
  let roundedWidth = width;
  let roundedHeight = height;

  // If the original width is a multiple of 320 then we should
  // not round up. This is to keep the native image dimensions
  // so that they match up with the actual frames from the video.
  //
  // For example 640x360, 960x540, 1280x720, 1920x1080
  //
  // Round up to nearest 100 px to improve cacheability at the
  // CDN. For example, any width between 601 pixels and 699
  // pixels will render the thumbnail at 700 pixels width.
  if (roundedWidth % 320 !== 0) {
    roundedWidth = Math.ceil(width / 100) * 100;
    roundedHeight = Math.round((roundedWidth / width) * height);
  }

  return {
    width: roundedWidth,
    height: roundedHeight
  };
}
</script>