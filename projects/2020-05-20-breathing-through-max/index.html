<!doctype html>
<html lang="en" class="no-js">
	<script>document.documentElement.classList.remove('no-js');</script>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
		<title>Breathing through Max</title>
		<meta name="description" content="I developed a system to follow and sonify the pace of breath, with an emphasis on the tenants of biofeedback, to serve as a responsive system for stress relief">
		<meta name="generator" content="Eleventy v3.0.0">

		
		<link rel="icon" href="icon/favicons/favicon.ico" sizes="32x32">
		<link rel="icon" href="icon/favicons/icon.svg" type="image/svg+xml">
		<link rel="apple-touch-icon" href="icon/favicons/apple-touch-icon.png">
		<link rel="manifest" href="icon/favicons/manifest.webmanifest">

		<link rel="preload" as="font" href="/font/Switzer-Variable.subset.woff2" crossorigin>
		<link rel="preload" as="font" href="/font/Rag-Regular.subset.woff2" crossorigin>
		<link rel="alternate" href="/feed/feed.xml" type="application/atom+xml" title="Jackson">
		<link rel="alternate" href="/feed/feed.json" type="application/json" title="Jackson">
		<style>
			/*
  Josh's Custom CSS Reset
  https://www.joshwcomeau.com/css/custom-css-reset/
*/
*,
*::before,
*::after {
	box-sizing: border-box;
}
* {
	line-height: calc(1em + 0.725rem);
	margin: 0;
}
body {
	-webkit-font-smoothing: antialiased;
}
img,
picture,
video,
canvas,
svg {
	display: block;
	max-width: 100%;
}
input,
button,
textarea,
select {
	font: inherit;
}
p,
h1,
h2,
h3,
h4,
h5,
h6 {
	overflow-wrap: break-word;
	margin: revert;
}
#root,
#__next {
	isolation: isolate;
}

		:root {
	--color-bg: white;
	--color-gray-20: #333333;
	--color-gray-50: #7f7f7f;
	--color-gray-90: #e5e5e5;
	--font-family: "Rag", -apple-system, system-ui, sans-serif;
	--font-family-monospace: Consolas, Menlo, Monaco, Andale Mono WT, Andale Mono,
		Lucida Console, Lucida Sans Typewriter, DejaVu Sans Mono,
		Bitstream Vera Sans Mono, Liberation Mono, Nimbus Mono L, Courier New,
		Courier, monospace;
	--syntax-tab-size: 2;
	--noise-img: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 600 600'%3E%3Cfilter id='a'%3E%3CfeTurbulence type='fractalNoise' baseFrequency='.65' numOctaves='3' stitchTiles='stitch'/%3E%3C/filter%3E%3Crect width='100%25' height='100%25' filter='url(%23a)'/%3E%3C/svg%3E");
	--noise-opacity: 0.2;
	/* Josh Comeau shadows */
	--shadow-color: 0deg 0% 0%;
	--shadow-elevation-low: 0px 0.2px 0.2px hsl(var(--shadow-color) / 0.16),
		0.1px 0.8px 0.8px -3px hsl(var(--shadow-color) / 0.13);
	--shadow-elevation-medium: 0px 0.2px 0.2px hsl(var(--shadow-color) / 0.15),
		0.1px 1px 1.1px -1.5px hsl(var(--shadow-color) / 0.13),
		0.3px 4.2px 4.4px -3px hsl(var(--shadow-color) / 0.11);
	--shadow-elevation-high: 0px 0.2px 0.2px hsl(var(--shadow-color) / 0.14),
		0.1px 1.3px 1.4px -0.6px hsl(var(--shadow-color) / 0.13),
		0.2px 2.8px 2.9px -1.2px hsl(var(--shadow-color) / 0.12),
		0.5px 5.7px 6px -1.8px hsl(var(--shadow-color) / 0.11),
		0.9px 10.9px 11.5px -2.4px hsl(var(--shadow-color) / 0.11),
		1.5px 19.3px 20.3px -3px hsl(var(--shadow-color) / 0.1);
	--nav-height: 4rem; /* Default height to lower for header*/
	color-scheme: light dark;
}

/* Both for system and user preference */
:root[data-theme="dark"],
.dark-mode {
	--color-bg: black;
	--color-gray-20: #cccccc;
	--color-gray-50: #808080;
	--color-gray-90: #1a1a1a;
	--noise-opacity: 0.1;
	color-scheme: dark;
}

@font-face {
	font-weight: 500;
	src: url("/font/Switzer-Variable.subset.woff2") format("woff2");
	font-family: "Switzer";
	font-display: swap;
	/* font-variation-settings: "wght" 400; */
}
@font-face {
	font-style: normal italic;
	font-weight: 400;
	src:
		url("/font/Rag-Regular.subset.woff2") format("woff2"),
		url("/font/Rag-Italic.subset.woff2") format("woff2"),
		url("/font/Rag-Bold.subset.woff2") format("woff2"),
		url("/font/Rag-BoldItalic.subset.woff2") format("woff2");
	font-family: "Rag";
	font-display: swap;
}

/* Only set the overflow to the root */
html {
	contain: paint;
}
html,
body {
	max-width: 100%;
	padding: 0;
	background-color: Canvas;
	background-color: transparent;
	color: CanvasText;
	font-family: var(--font-family);
}

body {
	display: flex;
	flex-direction: row;
	min-height: 100vh;
	width: 100%;
	max-width: calc(40rem + 200px + 2rem);
	margin: 0 auto;
	padding: 0 1rem;
}

.site-header {
	position: sticky;
	top: 0;
	align-self: flex-start;
	width: 200px;
	height: 100vh;
	flex-shrink: 0;
	padding: 1rem;
}

main {
	width: 100%;
	max-width: 40rem;
	padding: 1rem;

	& h1:first-child,
	& h2:first-child,
	& h3:first-child {
		margin-top: 0;
	}

	/* Add a margin for when chat bubble is absolute */
	&:where(.chat-active) {
		margin-top: 3rem;
	}
}

/* Typography */
h1,
h2,
h3 {
	margin-top: 1.5rem;
	margin-bottom: 1rem;
}

h1,
h2,
h3,
.letter {
	text-wrap: balance;
	width: fit-content;
	font-family: "Switzer";
}

/* https://www.a11yproject.com/posts/how-to-hide-content/ */
.visually-hidden {
	clip: rect(0 0 0 0);
	position: absolute;
	width: 1px;
	height: 1px;
	overflow: hidden;
	white-space: nowrap;
	clip-path: inset(50%);
}

p:last-child {
	margin-bottom: 0;
}

/* Post navigation */
.post-nav {
	display: flex;
	flex-direction: row;
	justify-content: space-between;
	align-items: center;
	margin-top: 1rem;
}

.post-nav a {
	display: flex;
	align-items: center;
	text-decoration: none;
	color: var(--color-gray-20);
	max-width: 100%;
}

.post-nav:has(.post-nav-prev):has(.post-nav-next) a {
	max-width: calc(50% - 1rem);
}

.post-nav-prev {
	margin-right: auto;
}

.post-nav-next {
	margin-left: auto;
}

.post-nav-title {
	overflow: hidden;
	white-space: nowrap;
	text-overflow: ellipsis;
}

.post-nav-arrow {
	flex-shrink: 0;
	padding: 0 0.25rem;
}

.post-nav-divider {
	padding: 0 0.5rem;
	color: var(--color-gray-50);
}

table {
	margin: 1rem 0;
}
table td,
table th {
	padding-right: 1rem;
}

pre {
	border-radius: 0.25rem;
	box-shadow: var(--shadow-elevation-low);
}
pre,
code {
	font-family: var(--font-family-monospace);
}
pre:not([class*="language-"]) {
	-moz-tab-size: var(--syntax-tab-size);
	-o-tab-size: var(--syntax-tab-size);
	-webkit-hyphens: none;
	-ms-hyphens: none;
	margin: 0.5rem 0;
	line-height: 1.375; /* 22px /16 */
	hyphens: none;
	direction: ltr;
	text-align: left;
	white-space: pre;
	word-break: normal;
	word-spacing: normal;
	tab-size: var(--syntax-tab-size);
}
code {
	word-break: break-all;
}

/* Header */
.home-link {
	margin-right: 2rem;
	font-weight: 700;
	font-size: 1rem; /* 16px /16 */
}
.home-link:link:not(:hover) {
	text-decoration: none;
}

/* Nav */
nav {
	position: relative;
	width: 100%;
	list-style: none;
}
.nav-item {
	display: inline-block;
	padding: 0.25rem 0;
}
.nav-item a[href]:not(:hover) {
	text-decoration: none;
}
.nav a[href][aria-current="page"] {
	text-decoration: underline;
}

/* Posts list */
.postlist {
	padding: 0;
	list-style: none;
}

/* Each item in a po */
.postlist-item {
	display: flex;
	position: relative;
	flex-wrap: wrap;
	align-items: baseline;
	margin-bottom: 1rem;
	padding-left: 1.5rem; /* Add left padding to make room for the arrow */

	&::before {
		position: absolute;
		top: 0.2rem;
		left: 0;
		margin-right: 0.5rem;
		transform: scale(1);
		content: "\2192"; /* Default to arrow */
		color: var(--color-gray-20);
		filter: saturate(100%);
		transition: all 0.5s ease-out;
	}

	&[data-emoji]::before {
		content: attr(data-emoji);
	}

	&:hover::before,
	&:focus-within::before {
		animation: pulseSat 2s linear infinite;
	}

	&:not(:hover)::before {
		transform: scale(1);
		animation: none;
		filter: saturate(100%);
	}

	.postlist-date::after {
		visibility: hidden;
		position: absolute;
		max-width: calc(100% - 12rem);
		padding-left: 1rem;
		overflow: hidden;
		content: attr(data-tooltip);
		color: var(--color-gray-20);
		text-overflow: ellipsis;
		white-space: nowrap;
		opacity: 0;
		transition:
			opacity 0.3s ease,
			visibility 0.3s ease;
	}

	&:has(.postlist-link:hover) .postlist-date::after {
		visibility: visible;
		opacity: 1;
	}

	&-active .postlist-link {
		font-weight: bold;
	}
}

@keyframes pulseSat {
	0%,
	50%,
	100% {
		transform: scale(1);
		filter: saturate(100%);
	}
	25% {
		transform: scale(0.8);
		filter: saturate(50%);
	}
	75% {
		transform: scale(1.2);
		filter: saturate(150%);
	}
}
.postlist-date {
	color: var(--color-gray-20);
	font-size: 0.8125rem; /* 13px /16 */
	word-spacing: -0.5px;
}
.postlist-link {
	flex-basis: 100%;
	font-weight: 700;
	font-size: 1.1875rem; /* 19px /16 */
	text-decoration-thickness: 1px;
	text-underline-position: from-font;
	text-underline-offset: 0;
}

/* Tags */
.post-tag {
	display: inline-flex;
	align-items: center;
	justify-content: center;
	font-style: italic;
	text-transform: capitalize;
}
.postlist-item > .post-tag {
	align-self: center;
}

/* Tags list */
.post-metadata {
	display: inline-flex;
	flex-wrap: wrap;
	margin: 0;
	padding: 0;
	gap: 0.5rem;
	list-style: none;
}
.post-metadata time {
	margin-right: 1rem;
}

/* Direct Links / Markdown Headers */
.header-anchor {
	margin-left: 0.1rem;
	font-style: normal;
	text-decoration: none;
}
a[href].header-anchor,
a[href].header-anchor:visited {
	color: transparent;
}
a[href].header-anchor:focus,
a[href].header-anchor:hover {
	text-decoration: underline;
}
a[href].header-anchor:focus,
:hover > a[href].header-anchor {
	color: #aaa;
}

h2 + .header-anchor {
	font-size: 1.5rem;
}

/* Figures */
figure {
	margin: 1rem 0;
}
figure > * {
	max-width: 100%;
	margin: 0 auto;
}
/* All images & videos should be in a figure */
figure :first-child {
	border-radius: 0.25rem;
	box-shadow: var(--shadow-elevation-low);
}

figcaption {
	margin-top: 0.5rem;
	color: var(--color-gray-50);
	text-align: center;
}

blockquote {
	padding-left: 1rem;
	border-left: 2px solid ButtonFace;
}

/* Talk bubble styling */
.nav-phrase {
	display: none;
	width: 100%;
	padding: 0 0.5rem;
	cursor: text;
}

.nav-bubble {
	display: flex;
	position: absolute;
	align-items: center;
	justify-content: space-between;
	width: calc(100% - 2.5rem);
	margin: 0;
	padding: calc(0.25rem - 1px);
	transform: translateY(calc(var(--item-top) - 12px));
	border: 1px solid var(--color-gray-90);
	border-radius: 0.25rem;
	background: ButtonFace;
	transition: transform 0.3s ease;

	&:before,
	&:after {
		position: absolute;
		top: 10px;
		right: -7.5px;
		width: 0;
		height: 0;
		border: 8px solid transparent;
		border-right: 0;
		content: "";
	}

	&:before {
		right: -9px;
		border-left-color: var(--color-gray-90);
	}

	&:after {
		border-left-color: ButtonFace;
	}

	/* Reset position when chat is active */
	&:where(.chat-active) {
		transform: none;
	}
}

/* Talk bubble movement */
header {
	/* We need to add 1 to the active item to account for the first item */
	--item-top: calc(12px + var(--nav-item-active, 1) * var(--nav-item-height));
	--nav-item-height: 36px;
	z-index: 1; /* Ensure the header is above other elements */

	display: flex;
	flex-direction: column;
	align-items: flex-end;
	justify-content: flex-start;
	width: 200px;
	height: 100vh;
	padding: 1rem;

	&:not(:has(+ .chat-active)) {
		&:has(.nav-item:nth-child(n):hover) {
			--n: var(--n);
			--item-top: calc(12px + (var(--n) - 1) * var(--nav-item-height));
		}
		&:has(.nav-item:nth-child(1):hover) {
			--n: 1;
		}
		&:has(.nav-item:nth-child(2):hover) {
			--n: 2;
		}
		&:has(.nav-item:nth-child(3):hover) {
			--n: 3;
		}
		&:has(.nav-item:nth-child(4):hover) {
			--n: 4;
		}
		&:has(.nav-item:nth-child(5):hover) {
			--n: 5;
		}
	}
}

.side-nav {
	display: flex;
	justify-content: center;
	width: 100%;
	padding-right: 2rem;
}

.nav-list {
	display: flex;
	z-index: 1;
	flex-direction: column;
	width: 100%;
	margin: 0;
	padding-right: 1rem;
	padding-inline-start: 0;
	list-style: none;
	text-align: right;
}

.theme-toggle {
	position: relative;
	right: -2.25rem;
	align-self: flex-start;
	margin-left: auto;
	transition: transform 0.3s ease;
}

#chat-toggle {
	cursor: pointer;
}

/* Dark mode toggle styles */
#dark-mode-toggle {
	display: none;
}

#dark-mode-toggle + label {
	border: none;
	background: none;
	font-size: 1rem;
	cursor: pointer;
}

#dark-mode-toggle + label::before {
	content: "üêì";
}

#dark-mode-toggle:checked + label::before {
	content: "üê∏";
}

@media (prefers-color-scheme: dark) {
	#dark-mode-toggle:not(:checked) + label::before {
		content: "üêì";
	}
	#dark-mode-toggle:checked + label::before {
		content: "üê∏";
	}
}

:root:has(#dark-mode-toggle:checked) {
	color-scheme: dark;
}

:root:has(#dark-mode-toggle:not(:checked)) {
	color-scheme: light;
}

/* Chat bubble related */
#user-input {
	width: 100%;
	/* Mozilla? */
	padding: 0;
	border: none;
	outline: none;
	background: none;
	color: inherit;
	font-size: inherit;
	font-family: inherit;
}

#user-input::placeholder,
.waiting {
	color: var(--color-gray-50);
	opacity: 0.7;
}

#chat-form {
	width: 100%;
}

#chat-form button {
	display: none;
}

@keyframes ellipsis {
	0% {
		content: ".";
	}
	33% {
		content: "..";
	}
	66% {
		content: "...";
	}
}

.waiting::after {
	display: inline-block;
	width: 1rem;
	content: ".";
	text-align: left;
	animation: ellipsis 1s infinite;
}

/* Chat reset */
.chat-reset {
	display: none;
	position: relative;
	align-self: flex-start;
	padding: 0 0.5rem;
	border: none;
	background: none;
	color: gray;
	cursor: pointer;
}

/* Add shadow to nav bubble */
.nav-bubble {
	box-shadow: var(--shadow-elevation-low);
}
.nav-bubble.chat-active {
	position: absolute;
	box-shadow: var(--shadow-elevation-medium);
}

.nav-bubble.chat-active .chat-reset {
	display: inline-block;
}

/* Only do nav switch on wide screens */
@media (min-width: 840px) {
	.nav-bubble {
		&:where(.chat-active) {
			/* left: calc(50% + 200px); */
			/* width: calc(640px - 200px); */
			left: calc(200px);
			width: calc(640px - 4.5rem);
		}

		&:where(.chat-active) > * {
			display: inline-block;
		}
	}
}

/* For mobile view */
@media (max-width: 839px) {
	/* Switch side nav off */
	.side-nav {
		display: none;
	}

	/* Mobile */
	.nav-phrase {
		display: inline-block;
	}

	body {
		flex-direction: column; /* Stack header and main content on narrow screens */
		max-width: 40rem;
		padding: 0;
	}

	main {
		max-width: none;
		padding: 1rem;
	}

	.site-header {
		position: relative;
		width: 100%; /* Full width on narrow screens */
		max-width: 640px;
		height: auto;
		padding-bottom: 0;
		gap: 1rem 0.5rem;
	}

	/* Mobile-specific nav bubble styles */
	.nav-bubble {
		position: relative;
		left: initial;
		transform: none;
	}

	header {
		position: relative;
		height: auto;
		width: 100%;
		align-items: flex-start;
	}
}

/* Util */
.line-clamp {
	-webkit-box-orient: vertical;
	display: -webkit-box;
	line-clamp: 2;
	-webkit-line-clamp: 2;
	overflow: hidden;
}

.noise-container {
	z-index: -1;
	position: fixed;
	top: 0;
	left: 0;
	width: 100%;
	height: 100%;
	background-image: var(--noise-img);
	background-size: 182px;
	background-repeat: repeat;
	opacity: var(--noise-opacity);
	pointer-events: none;
}

/* Spotify widget */
.spotify-widget img {
	display: inline-block;
	border-radius: 0.25rem;
	box-shadow: var(--shadow-elevation-low);
}

/* Sidebar progress bar */
.progress-bar {
	position: fixed;
	top: 0;
	left: 0;
	width: 0.5rem;
	height: 100vh;
	transform: scaleY(0);
	transform-origin: 0 0;
	background-color: var(--color-gray-50);
}

@supports (animation-timeline: scroll()) {
	html {
		-ms-overflow-style: none; /* Internet Explorer 10+ */
		scrollbar-width: none; /* Firefox */
	}

	html::-webkit-scrollbar {
		display: none; /* Chrome, Safari, and Opera */
		width: 0;
		height: 0;
	}

	.progress-bar {
		animation-timeline: scroll(root block);
		animation-range: entry 0% cover 100%;
		animation: grow-progress linear;
	}

	@keyframes grow-progress {
		to {
			transform: scaleY(1);
		}
	}
}

/* Citation */
.citation {
	margin-bottom: 1rem;
	padding-left: 2rem;
	text-indent: -2rem;
}

.citation p {
	margin: 0;
}

/* Search results */
#search-results {
	max-height: 50vh;
	overflow-y: auto;
}
#search-results:has(.search-result) {
	margin-top: 0.25rem;
	border-top: 1px solid var(--color-gray-90);
}

.search-result {
	--border-width: 0px;
	display: block;
	padding: 0.5rem 1rem;
	border-bottom: 1px solid var(--color-gray-90);
	background: linear-gradient(var(--color-gray-50), var(--color-gray-50))
		left/var(--border-width) 100% no-repeat;
	color: inherit;
	text-decoration: none;
	transition: 0.3s ease;
	transition-property: background-size, background-color;
}

.search-result:hover {
	--border-width: 3px;
	background-color: var(--color-gray-90);
}

.search-result a {
	color: var(--color-gray-20);
	font-weight: bold;
	text-decoration: none;
}

.search-result p {
	margin: 0;
	color: var(--color-gray-50);
}

/* Wave divider */
#post-title {
	margin-bottom: 0.5rem;
}

:root {
	--wave-width: 30px;
	--wave-height: 10px;
}

.wave-divider {
	width: 100%;
	height: var(--wave-height);
	margin: 2rem 0;
	/* margin-top: 0.3rem;
	margin-bottom: 1rem; */
	background-color: var(--emoji-color);

	/* Wave mask */
	--wave-mask: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='60' height='10'%3E%3Cpath d='M0 5q15-5 30 0t30 0' stroke='white' fill='none' stroke-width='1.5'/%3E%3C/svg%3E");

	/* Fade-out mask */
	--fade-mask: linear-gradient(
		to right,
		transparent,
		black 15%,
		black 85%,
		transparent
	);

	/* Combine masks */
	mask-image: var(--wave-mask), var(--fade-mask);
	mask-size:
		var(--wave-width) var(--wave-height),
		100% 100%;
	mask-repeat: repeat-x, no-repeat;
	mask-composite: intersect;

	/* For webkit browsers */
	-webkit-mask-image: var(--wave-mask), var(--fade-mask);
	-webkit-mask-size:
		var(--wave-width) var(--wave-height),
		100% 100%;
	-webkit-mask-repeat: repeat-x, no-repeat;
	-webkit-mask-composite: source-in;

	animation: wave-animation 5s linear infinite;
}

@keyframes wave-animation {
	0% {
		mask-position:
			0 0,
			0 0;
		-webkit-mask-position:
			0 0,
			0 0;
	}
	100% {
		mask-position:
			var(--wave-width) 0,
			0 0;
		-webkit-mask-position:
			var(--wave-width) 0,
			0 0;
	}
}


		
		
			/* PrismJS 1.29.0
https://prismjs.com/download.html#themes=prism-tomorrow&languages=markup+css+clike+javascript+bash+python */
code[class*=language-],pre[class*=language-]{color:#ccc;background:0 0;font-family:Consolas,Monaco,'Andale Mono','Ubuntu Mono',monospace;font-size:1em;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto}:not(pre)>code[class*=language-],pre[class*=language-]{background:#2d2d2d}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal}.token.block-comment,.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#999}.token.punctuation{color:#ccc}.token.attr-name,.token.deleted,.token.namespace,.token.tag{color:#e2777a}.token.function-name{color:#6196cc}.token.boolean,.token.function,.token.number{color:#f08d49}.token.class-name,.token.constant,.token.property,.token.symbol{color:#f8c555}.token.atrule,.token.builtin,.token.important,.token.keyword,.token.selector{color:#cc99cd}.token.attr-value,.token.char,.token.regex,.token.string,.token.variable{color:#7ec699}.token.entity,.token.operator,.token.url{color:#67cdcc}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}.token.inserted{color:green}

			lite-youtube {
    background-color: #000;
    position: relative;
    display: block;
    contain: content;
    background-position: center center;
    background-size: cover;
    cursor: pointer;
    max-width: 720px;
}

/* gradient */
lite-youtube::before {
    content: attr(data-title);
    display: block;
    position: absolute;
    top: 0;
    /* Pixel-perfect port of YT's gradient PNG, using https://github.com/bluesmoon/pngtocss plus optimizations */
    background-image: linear-gradient(180deg, rgb(0 0 0 / 67%) 0%, rgb(0 0 0 / 54%) 14%, rgb(0 0 0 / 15%) 54%, rgb(0 0 0 / 5%) 72%, rgb(0 0 0 / 0%) 94%);
    height: 99px;
    width: 100%;
    font-family: "YouTube Noto",Roboto,Arial,Helvetica,sans-serif;
    color: hsl(0deg 0% 93.33%);
    text-shadow: 0 0 2px rgba(0,0,0,.5);
    font-size: 18px;
    padding: 25px 20px;
    overflow: hidden;
    white-space: nowrap;
    text-overflow: ellipsis;
    box-sizing: border-box;
}

lite-youtube:hover::before {
    color: white;
}

/* responsive iframe with a 16:9 aspect ratio
    thanks https://css-tricks.com/responsive-iframes/
*/
lite-youtube::after {
    content: "";
    display: block;
    padding-bottom: calc(100% / (16 / 9));
}
lite-youtube > iframe {
    width: 100%;
    height: 100%;
    position: absolute;
    top: 0;
    left: 0;
    border: 0;
}

/* play button */
lite-youtube > .lty-playbtn {
    display: block;
    /* Make the button element cover the whole area for a large hover/click target‚Ä¶ */
    width: 100%;
    height: 100%;
    /* ‚Ä¶but visually it's still the same size */
    background: no-repeat center/68px 48px;
    /* YT's actual play button svg */
    background-image: url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 68 48"><path d="M66.52 7.74c-.78-2.93-2.49-5.41-5.42-6.19C55.79.13 34 0 34 0S12.21.13 6.9 1.55c-2.93.78-4.63 3.26-5.42 6.19C.06 13.05 0 24 0 24s.06 10.95 1.48 16.26c.78 2.93 2.49 5.41 5.42 6.19C12.21 47.87 34 48 34 48s21.79-.13 27.1-1.55c2.93-.78 4.64-3.26 5.42-6.19C67.94 34.95 68 24 68 24s-.06-10.95-1.48-16.26z" fill="red"/><path d="M45 24 27 14v20" fill="white"/></svg>');
    position: absolute;
    cursor: pointer;
    z-index: 1;
    filter: grayscale(100%);
    transition: filter .1s cubic-bezier(0, 0, 0.2, 1);
    border: 0;
}

lite-youtube:hover > .lty-playbtn,
lite-youtube .lty-playbtn:focus {
    filter: none;
}

/* Post-click styles */
lite-youtube.lyt-activated {
    cursor: unset;
}
lite-youtube.lyt-activated::before,
lite-youtube.lyt-activated > .lty-playbtn {
    opacity: 0;
    pointer-events: none;
}

.lyt-visually-hidden {
    clip: rect(0 0 0 0);
    clip-path: inset(50%);
    height: 1px;
    overflow: hidden;
    position: absolute;
    white-space: nowrap;
    width: 1px;
  }
		</style>
	</head>

	<body style="--nav-item-active: 1;">
		<div class="noise-container"></div>
		<a href="#skip" class="visually-hidden">Skip to main content</a>

		<header class="site-header">
			<nav>
				<h2 class="visually-hidden">Top level navigation menu</h2>
				<div class="nav-bubble">
    <button id="chat-reset" class="chat-reset" aria-label="Reset chat">‚Ü∫</button>
    <div id="navPhrase" class="nav-phrase">
        
            
            <a href="/" style="text-decoration: none;">Home</a>&emsp;<a href="/projects/" style="text-decoration: none;">Projects</a>&emsp;<a href="/blog/" style="text-decoration: none;">Blog</a>&emsp;<a href="/about/" style="text-decoration: none;">About Me</a>
        
    </div>
    <form method="post" id="theme-form" class="theme-toggle">
        <input type="checkbox" id="dark-mode-toggle" name="theme" value="dark" aria-label="Toggle dark mode">
        <label for="dark-mode-toggle"></label>
    </form>
</div>
				<div class="side-nav">
					<ul class="nav-list">
						<li id="chat-toggle" class="nav-item">Welcome!</li>
							<li class="nav-item">
								<a href="/">Home</a>
							</li>
							<li class="nav-item">
								<a href="/projects/">Projects</a>
							</li>
							<li class="nav-item">
								<a href="/blog/">Blog</a>
							</li>
							<li class="nav-item">
								<a href="/about/">About Me</a>
							</li>
					</ul>
				</div>
			</nav>
		</header>

		<main id="skip">
			


<div class="progress-bar"></div>

<article class="post">
  <h1 id="post-title">
    Breathing through Max&ensp;üßò
  </h1>

  <ul class="post-metadata">
    <li>
      <time datetime="2020-05-18">18 May 2020</time>
    </li>
      <li>
        <a href="/tags/projects/" class="post-tag">projects</a>
      </li>
  </ul>

  <div class="wave-divider" style="--emoji-color: #de9924;"></div>

  <h2 id="rationale" tabindex="-1">Rationale <a class="header-anchor" href="#rationale">#</a></h2>
<p>Analyzing motion from smartphone sensors or laptop cameras is a both a challenging scenario and exciting opportunity. This project transforms the live acceleration data recorded from an iPhone resting on the torso of a person laying down into a dynamic sonic atmosphere that may enhance the monitoring one‚Äôs breath through auditory cues. One potential use of this system would be as a meditation or relaxation assistant. The sound environment aims to be soothing and ought to coax one into a deeper and more rhythmic breathing cycle. There is ample empirical data to suggest that paced respiration can reduce anxiety and other measures of perceived stress. Following common themes of this literature, <a href="https://en.wikipedia.org/wiki/Biofeedback">biofeedback</a> is a topic of importance in recognizing the effects of this system on a user.</p>
<p>The inhales and exhales are identified as peaks and troughs within the accelerometer data and as a result, an average breathing rate can be obtained that serves as a marker of how consistently rhythmic the individual‚Äôs breathing rate is. This indicator is used to grow and shrink the sonic environment as one‚Äôs breathing and body begin to settle. On the surface, the information gained from the chest‚Äôs rise and fall appear to be an easy to manipulate stream. However, most of the time spent on the project involved developing a reliable and flexible model for processing a very noisy stream of data due to the micro-movements that were being recorded. Various parameters of the system were then modulated by other much more noisy sensor data as well.</p>
<h2 id="methodology" tabindex="-1">Methodology <a class="header-anchor" href="#methodology">#</a></h2>
<p>The first task before embarking on this project was finding a suitable app that would be a reliable recorder and streaming platform for micro-motion data. Sadly, there are not many apps that provide a data logging functionality on iOS and even fewer that provide a way to record data from the sensors and only one that appears to meet the requirements I had for such an app,</p>
<ol>
<li>Log data at a high frequency (&gt; 50hz)</li>
<li>Record multiple sensors at once</li>
<li>Export this data in CSV format and</li>
<li>Send this data over a networked connection</li>
</ol>
<p>Most of these apps transmit their sensor data over a UDP connection using the OSC protocol. This type of communication is well supported by many DAWs and platforms like Max and Pure Data. However, the app that was used, SensorLog unfortunately, did not send data with the OSC protocol. Instead, it sends the data over UDP as it would when writing a CSV file that was not compatible with Max‚Äôs [udpreceive] object.</p>
<p>To work around this, I wrote a python script that acted as a node to receive, format the stream into proper OSC messages, and finally, send the data locally to a specified port within Max. The script operated by receiving a row of data, splitting the list of data points into an array, and then sending each index of the array as a pair with a specified OSC message. I used the messages ‚Äú/x‚Äù, ‚Äú/y‚Äù, and ‚Äú/z‚Äù as shorthand for the x, y, z, acceleration data. Once this was passed into Max, the data was able to be handled the same way as any other OSC message.</p>
<figure><img src="/img/breathing-code.png" alt="Sample of the code used to transport the messages into Max" loading="lazy" decoding="async" /><figcaption>Sample of the code used to transport the messages into Max</figcaption></figure>
<p>After some initial testing of various sensors and positions during recording, I found that the acceleration value for the y-axis was the most reliable source of information for tracking respiratory motion. Because of the placement of the phone, none of the other sensors render any useful information. The only other sensor that appeared to follow the same information was the gyroscope, but the sensor upon inspection looked like a transformation of the acceleration data. In the first trial recording set of breathing, I was able to find that this sensor‚Äôs y-axis extracted recognizable oscillations of the rise and fall of my stomach. However, because the movements were quite small, the noise of the sensor clouded what was, in reality, a smooth envelope of motion.</p>
<p>Reading the CSV data into Max was achieved by loading each line of the CSV as a text file from which I could use a [metro] object to iterate through the [coll] dictionary that stored the sensor data (<a href="https://cycling74.com/forums/importing-from-excel-csv-questions/">I stole this bit of Max data</a>). From Max, I could visualize the data stream easily using a [multislider] window. I then set out to smooth this data through a variety of techniques. I found that a reliable method of smoothing the noisy data was to create a buffer of the last x number of samples (with [zl.stream]) and then output the mean ([mean]) of that sliding window. The larger the number of samples, the smoother the data, yet this stunts some of the local dynamics within the stream and creates latency. After exploring further I found a 3rd party object [dot.denoise.sliding] that includes better logic for excluding outliers within streams.</p>
<figure><img src="/img/breathing-noisey.png" alt="Before and after de-noising the stream" loading="lazy" decoding="async" /><figcaption>Before and after de-noising the stream</figcaption></figure>
<p>This returns to an observation I noticed when looking at sensor data. I noticed that one of the gyroscope sensors also was repeating in a rhythmic pattern, but much faster and pronounced than breathing should be. I realized that these were pronounced fulgurations of my heartbeat and that these impulses were actually affecting the accelerometer sensor data I was analyzing from the y-axis.</p>
<figure><img src="/img/breathing-gyro.png" alt="Notice the fast paced impulses from the gyroscope sensor" loading="lazy" decoding="async" /><figcaption>Notice the fast paced impulses from the gyroscope sensor</figcaption></figure>
<p>Once the oscillations were smoothed, the next step was identifying local minimums and maximums of each breath. Again, the dot library had a nifty object to find local max/mins by checking for changes in sign (+/-) from a previous data point to the next. This would have worked nicely if the data rose and fell with continuity. But due to the noise, there were a number of places near the peak or trough of the oscillations where even a smoothed data point might change the sign of the differences between the current and previous point.</p>
<p>I tried number of techniques to suppress the improper max/mins that would appear such as forcing a minimum delay to check for a max after finding a min or max, as well as attempting to doubly embed local max/min detection. The most successful and flexible method by far was setting a minimum distance between the breaths that were taken. This is a reliable method as a single breath could vary in speed and the expansion of the torso would be the same.</p>
<p>I further enhanced this solution by making the distance dynamically shift by an average of the distance between the last five maxes and mins.</p>
<figure><img src="/img/breathing-distance.png" alt="Gating the frequent max/mins" loading="lazy" decoding="async" /><figcaption>Gating the frequent max/mins</figcaption></figure>
<p>Finally, the last piece of data that is inferred from identifying the local max/mins of each breath is the average time between each inhale and exhale. This is calculated as a metric of respiratory rate consistency which is the difference between the last period between a max/min and the average of these last 10 periods. This value is then scaled and used to attenuate a sound clip of wind chimes that enter when the consistency value is low. Thus, the wind chimes should emerge as a result of a restful cycle of breath and provide positive feedback to the user. In addition to the wind chime samples, there is a three-oscillator drone instrument was driven by the noisy data from the x and z-axis accelerometer streams. This drone adds a subtle resonance to the bells and provides some ambient feedback of the motion of the breath. This is achieved by scaling the smoothed acceleration data from the y-axis and modulating the amplitude.</p>
<h2 id="results-and-conclusions" tabindex="-1">Results and Conclusions <a class="header-anchor" href="#results-and-conclusions">#</a></h2>
<p>After debugging the system for quite some time, I may not be able to provide the best perspective on how useful it is for its intended purpose. Even still, the system may allow a user to pay attention to their biorhythms and less to other distracting thoughts that might interrupt a session. Most of the time spent building the system was in an effort to fine-tune the analysis of these data streams in real-time so many of the acoustic elements were secondary to this objective. The streams were processed flexibly and reliably for the dynamic stream and I‚Äôm quite happy with the way the data is handled throughout the system ‚Äì even in extreme cases such as erratic motion where the amplitude of all sounds is reduced to silence. From this perspective, I find the system quite usable but I am not entirely pleased with the sound of the instruments and sonic environments.</p>
<p>There are still some unanswered questions I have about more technical aspects of the system. The first being the latency contributed form formatting UDP messages in a Python node and then passing it on to Max. I was fine with this compromise considering the app‚Äôs considerable logging speed (100Hz) which enabled much of the noise to be averaged. Another question is one of compatibility: If I were to use another sensor app that was able to directly send OSC data, perhaps at a lower logging rate, would this dramatically affect the system‚Äôs ability to identify peaks and troughs? For future work, the system‚Äôs reception logic should allow general purpose OSC enabled apps to connect to the system in addition to SensorLog for better compatibility.</p>
<p>You can find the code <a href="https://github.com/jacksongoode/breathingthroughmax">here</a> along with a setup.</p>
<figure>
    <div class="iframe-wrapper pb-169">
        <iframe src="https://drive.google.com/file/d/1G64dQ5iub0O7MClNNkbH5ktVX5hHf0e8/preview" frameborder="0"  allowfullscreen alt="A demo of the system"></iframe>
    </div>
    <figcaption>A demo of the system using pre-recorded data</figcaption>
</figure>
<h2 id="works-cited" tabindex="-1">Works Cited <a class="header-anchor" href="#works-cited">#</a></h2>
<p class="citation">Upham, Finn. (2016). <em>Breathing in Music: Measuring and Marking Time</em>. Retrieved from <a href="https://finnupham.com/2016/10/17/breathing-in-music-making-time-in-music-2016/">https://finnupham.com/2016/10/17/breathing-in-music-making-time-in-music-2016/</a></p>
<p class="citation">Siwiak, Diana, et al.. (2009). <em>Catch Your Breath - Musical Biofeedback for Breathing Regulation</em>. Retrieved from <a href="http://www.aes.org/e-lib/online/browse.cfm?elib=15065">http://www.aes.org/e-lib/online/browse.cfm?elib=15065</a></p>
<p class="citation">Sutarto, Auditya Purwandini, et al.. (2012). <em>Resonant Breathing Biofeedback Training for Stress Reduction Among Manufacturing Operators</em>. Retrieved from <a href="https://doi.org/10.1080/10803548.2012.11076959">https://doi.org/10.1080/10803548.2012.11076959</a></p>


  <div class="wave-divider" style="--emoji-color: #de9924;"></div>
    <nav class="post-nav">
        <a href="/projects/2020-04-08-soniweb-2/" class="post-nav-prev">
          <span class="post-nav-arrow">‚Üê</span>
          <span class="post-nav-title">Soniweb: Epilogue</span>
        </a>
        <span class="post-nav-divider">‚Ä¢</span>
        <a href="/projects/2020-09-20-classifying-urban-sounds/" class="post-nav-next">
          <span class="post-nav-title">Classifying Urban Sounds in a Multi-label Database</span>
          <span class="post-nav-arrow">‚Üí</span>
        </a>
    </nav>
</article>
		</main>

		<footer></footer>

		<!-- This page `/projects/2020-05-20-breathing-through-max/` was built on 2024-09-25T07:22:19.283Z -->
	</body>
</html>
<script defer>
	// Minimal JS for handling user preference
(function () {
    const toggle = document.getElementById('dark-mode-toggle');

    // Set initial state based on localStorage or system preference
    const storedTheme = localStorage.getItem('color-scheme');
    if (storedTheme) {
        document.documentElement.setAttribute('data-theme', storedTheme);
        toggle.checked = storedTheme === 'dark';
    }

    // Handle toggle changes
    toggle.addEventListener('change', () => {
        const newTheme = toggle.checked ? 'dark' : 'light';
        document.documentElement.setAttribute('data-theme', newTheme);
        localStorage.setItem('color-scheme', newTheme);
    });

    // const form = document.getElementById('theme-form');
    // Handle form submission (for no-JS fallback)
    // form.addEventListener('submit', (e) => {
    //     e.preventDefault();
    //     const formData = new FormData(form);
    //     fetch('/set-theme', {
    //         method: 'POST',
    //         body: formData
    //     }).then(() => {
    //         location.reload();
    //     });
    // });
})();

		// Generate a random user ID if not already stored
function getUserId() {
	return (
		localStorage.getItem("userId") ||
		localStorage.setItem(
			"userId",
			"user_" + Math.random().toString(36).slice(2, 11),
		)
	);
}

function sendMessageToWorker(message) {
	const baseUrl =
		window.location.hostname === "localhost" ||
		window.location.hostname === "127.0.0.1"
			? "http://localhost:8090"
			: "";
	const isDarkMode =
		document.documentElement.getAttribute("data-theme") === "dark";
	const animalParam = isDarkMode ? "frog" : "chicken";

	updateNavPhrase(isDarkMode ? "Ribbit" : "Cluck", true);

	// Get the body content
	const bodyContent = document.body.innerText;

	// Prepare the message with the body content
	const fullMessage = `Current page content:\n${bodyContent}\n\nUser message: ${message}`;

	fetch(
		`${baseUrl}/ai?message=${encodeURIComponent(fullMessage)}&animal=${animalParam}&userId=${getUserId()}`,
	)
		.then((response) => {
			if (!response.ok)
				throw new Error(`HTTP error! status: ${response.status}`);
			return response.body.getReader();
		})
		.then((reader) => {
			let accumulatedResponse = "";

			function readStream() {
				let buffer = "";
				reader.read().then(function processText({ done, value }) {
					if (done) {
						updateNavPhrase(accumulatedResponse, false);
						return;
					}

					buffer += new TextDecoder().decode(value);
					let newlineIndex;
					while ((newlineIndex = buffer.indexOf("\n")) !== -1) {
						const line = buffer.slice(0, newlineIndex);
						buffer = buffer.slice(newlineIndex + 1);

						if (line.startsWith("data: ")) {
							try {
								const jsonStr = line.slice(5).trim();
								if (jsonStr === "[DONE]") {
									updateNavPhrase(accumulatedResponse, false);
									return;
								}
								const data = JSON.parse(jsonStr);
								if (data.response) {
									accumulatedResponse += data.response;
									updateNavPhrase(accumulatedResponse, false);
								}
							} catch (error) {
								buffer = line + "\n" + buffer;
								break;
							}
						}
					}

					return reader.read().then(processText);
				});
			}

			readStream();
		})
		.catch((error) => {
			console.error("Fetch error:", error);
			updateNavPhrase("Sorry, something went wrong.");
		});
}

function updateNavPhrase(text, isWaiting = false) {
	const navPhrase = document.getElementById("navPhrase");
	navPhrase.textContent = text;
	navPhrase.classList.toggle("waiting", isWaiting);
	navPhrase.classList.toggle("clickable", !isWaiting && text.length > 0);
}

document.addEventListener("DOMContentLoaded", function () {
	const chatTrigger = document.getElementById("chat-toggle");
	const talkBubble = document.querySelector(".nav-bubble");
	const mainContent = document.querySelector("main");
	const navPhrase = document.getElementById("navPhrase");
	const chatReset = document.getElementById("chat-reset");
	let originalContent = navPhrase.innerHTML;

	function resetChatInterface() {
		navPhrase.innerHTML = originalContent;
		talkBubble.classList.remove("chat-active");
		mainContent.classList.remove("chat-active");
	}

	chatReset.addEventListener("click", resetChatInterface);

	function activateChatInterface() {
		navPhrase.innerHTML = `
		<form id="chat-form">
		  <input type="text" id="user-input" placeholder="Search... or say hi?">
		  <button type="submit" style="display:none;">Send</button>
		</form>
		<div id="search-results"></div>
	  `;
		document.getElementById("user-input").focus();

		const searchResults = document.getElementById("search-results");
		let pagefind;

		document
			.getElementById("user-input")
			.addEventListener("input", async function () {
				if (!pagefind) {
					pagefind = await import("/pagefind/pagefind.js");
					await pagefind.options({
						element: "#search-results",
						excerptLength: 15,
						highlightParam: "highlight",
					});
					await pagefind.init();
				}

				const query = this.value.trim();
				if (query.length > 2) {
					const search = await pagefind.search(query);
					const results = await Promise.all(
						search.results.map((r) => r.data()),
					);

					searchResults.innerHTML =
						results.length > 0
							? results
									.map(
										(result) => `
			<a href="${result.url}" class="search-result">
			  <div class="search-result-title">${result.meta.title || "Untitled"}</div>
			  <p>${result.excerpt}</p>
			</a>
		  `,
									)
									.join("")
							: "";
					talkBubble.classList.add("chat-active");
				} else {
					searchResults.innerHTML = "";
				}
			});

		document
			.getElementById("chat-form")
			.addEventListener("submit", function (e) {
				e.preventDefault();
				const userInput = document.getElementById("user-input");
				if (userInput.value.trim() !== "") {
					sendMessageToWorker(userInput.value.trim());
					userInput.value = "";
					searchResults.innerHTML = "";
				}
			});

		document
			.getElementById("user-input")
			.addEventListener("keydown", function (e) {
				if (e.key === "Escape") resetChatInterface();
			});
	}

	function handleChatTrigger() {
		talkBubble.classList.toggle("chat-active");
		mainContent.classList.toggle("chat-active");
		talkBubble.classList.contains("chat-active")
			? activateChatInterface()
			: (navPhrase.innerHTML = originalContent);
	}

	chatTrigger.addEventListener("click", handleChatTrigger);

	navPhrase.addEventListener("click", function (event) {
		if (event.target.tagName.toLowerCase() === "a") return;
		if (
			window.innerWidth < 840 &&
			!talkBubble.classList.contains("chat-active")
		) {
			handleChatTrigger();
		} else if (navPhrase.classList.contains("clickable")) {
			activateChatInterface();
			navPhrase.classList.remove("clickable");
		}
	});
});


		
			
			/**
 * A lightweight youtube embed. Still should feel the same to the user, just MUCH faster to initialize and paint.
 *
 * Thx to these as the inspiration
 *   https://storage.googleapis.com/amp-vs-non-amp/youtube-lazy.html
 *   https://autoplay-youtube-player.glitch.me/
 *
 * Once built it, I also found these:
 *   https://github.com/ampproject/amphtml/blob/master/extensions/amp-youtube (üëçüëç)
 *   https://github.com/Daugilas/lazyYT
 *   https://github.com/vb/lazyframe
 */
class LiteYTEmbed extends HTMLElement {
    connectedCallback() {
        this.videoId = this.getAttribute('videoid');

        let playBtnEl = this.querySelector('.lty-playbtn');
        // A label for the button takes priority over a [playlabel] attribute on the custom-element
        this.playLabel = (playBtnEl && playBtnEl.textContent.trim()) || this.getAttribute('playlabel') || 'Play';

        this.dataset.title = this.getAttribute('title') || "";

        /**
         * Lo, the youtube poster image!  (aka the thumbnail, image placeholder, etc)
         *
         * See https://github.com/paulirish/lite-youtube-embed/blob/master/youtube-thumbnail-urls.md
         */
        if (!this.style.backgroundImage) {
          this.style.backgroundImage = `url("https://i.ytimg.com/vi/${this.videoId}/hqdefault.jpg")`;
          this.upgradePosterImage();
        }

        // Set up play button, and its visually hidden label
        if (!playBtnEl) {
            playBtnEl = document.createElement('button');
            playBtnEl.type = 'button';
            playBtnEl.classList.add('lty-playbtn');
            this.append(playBtnEl);
        }
        if (!playBtnEl.textContent) {
            const playBtnLabelEl = document.createElement('span');
            playBtnLabelEl.className = 'lyt-visually-hidden';
            playBtnLabelEl.textContent = this.playLabel;
            playBtnEl.append(playBtnLabelEl);
        }

        this.addNoscriptIframe();

        // for the PE pattern, change anchor's semantics to button
        if(playBtnEl.nodeName === 'A'){
            playBtnEl.removeAttribute('href');
            playBtnEl.setAttribute('tabindex', '0');
            playBtnEl.setAttribute('role', 'button');
            // fake button needs keyboard help
            playBtnEl.addEventListener('keydown', e => {
                if( e.key === 'Enter' || e.key === ' ' ){
                    e.preventDefault();
                    this.activate();
                }
            });
        }

        // On hover (or tap), warm up the TCP connections we're (likely) about to use.
        this.addEventListener('pointerover', LiteYTEmbed.warmConnections, {once: true});
        this.addEventListener('focusin', LiteYTEmbed.warmConnections, {once: true});

        // Once the user clicks, add the real iframe and drop our play button
        // TODO: In the future we could be like amp-youtube and silently swap in the iframe during idle time
        //   We'd want to only do this for in-viewport or near-viewport ones: https://github.com/ampproject/amphtml/pull/5003
        this.addEventListener('click', this.activate);

        // Chrome & Edge desktop have no problem with the basic YouTube Embed with ?autoplay=1
        // However Safari desktop and most/all mobile browsers do not successfully track the user gesture of clicking through the creation/loading of the iframe,
        // so they don't autoplay automatically. Instead we must load an additional 2 sequential JS files (1KB + 165KB) (un-br) for the YT Player API
        // TODO: Try loading the the YT API in parallel with our iframe and then attaching/playing it. #82
        this.needsYTApi = this.hasAttribute("js-api") || navigator.vendor.includes('Apple') || navigator.userAgent.includes('Mobi');
    }

    /**
     * Add a <link rel={preload | preconnect} ...> to the head
     */
    static addPrefetch(kind, url, as) {
        const linkEl = document.createElement('link');
        linkEl.rel = kind;
        linkEl.href = url;
        if (as) {
            linkEl.as = as;
        }
        document.head.append(linkEl);
    }

    /**
     * Begin pre-connecting to warm up the iframe load
     * Since the embed's network requests load within its iframe,
     *   preload/prefetch'ing them outside the iframe will only cause double-downloads.
     * So, the best we can do is warm up a few connections to origins that are in the critical path.
     *
     * Maybe `<link rel=preload as=document>` would work, but it's unsupported: http://crbug.com/593267
     * But TBH, I don't think it'll happen soon with Site Isolation and split caches adding serious complexity.
     */
    static warmConnections() {
        if (LiteYTEmbed.preconnected) return;

        // The iframe document and most of its subresources come right off youtube.com
        LiteYTEmbed.addPrefetch('preconnect', 'https://www.youtube-nocookie.com');
        // The botguard script is fetched off from google.com
        LiteYTEmbed.addPrefetch('preconnect', 'https://www.google.com');

        // Not certain if these ad related domains are in the critical path. Could verify with domain-specific throttling.
        LiteYTEmbed.addPrefetch('preconnect', 'https://googleads.g.doubleclick.net');
        LiteYTEmbed.addPrefetch('preconnect', 'https://static.doubleclick.net');

        LiteYTEmbed.preconnected = true;
    }

    fetchYTPlayerApi() {
        if (window.YT || (window.YT && window.YT.Player)) return;

        this.ytApiPromise = new Promise((res, rej) => {
            var el = document.createElement('script');
            el.src = 'https://www.youtube.com/iframe_api';
            el.async = true;
            el.onload = _ => {
                YT.ready(res);
            };
            el.onerror = rej;
            this.append(el);
        });
    }

    /** Return the YT Player API instance. (Public L-YT-E API) */
    async getYTPlayer() {
        if(!this.playerPromise) {
            await this.activate();
        }

        return this.playerPromise;
    }

    async addYTPlayerIframe() {
        this.fetchYTPlayerApi();
        await this.ytApiPromise;

        const videoPlaceholderEl = document.createElement('div')
        this.append(videoPlaceholderEl);

        const paramsObj = Object.fromEntries(this.getParams().entries());

        this.playerPromise = new Promise(resolve => {
            let player = new YT.Player(videoPlaceholderEl, {
                width: '100%',
                videoId: this.videoId,
                playerVars: paramsObj,
                events: {
                    'onReady': event => {
                        event.target.playVideo();
                        resolve(player);
                    }
                }
            });
        });
    }

    // Add the iframe within <noscript> for indexability discoverability. See https://github.com/paulirish/lite-youtube-embed/issues/105
    addNoscriptIframe() {
        const iframeEl = this.createBasicIframe();
        const noscriptEl = document.createElement('noscript');
        // Appending into noscript isn't equivalant for mysterious reasons: https://html.spec.whatwg.org/multipage/scripting.html#the-noscript-element
        noscriptEl.innerHTML = iframeEl.outerHTML;
        this.append(noscriptEl);
    }

    getParams() {
        const params = new URLSearchParams(this.getAttribute('params') || []);
        params.append('autoplay', '1');
        params.append('playsinline', '1');
        return params;
    }

    async activate(){
        if (this.classList.contains('lyt-activated')) return;
        this.classList.add('lyt-activated');

        if (this.needsYTApi) {
            return this.addYTPlayerIframe(this.getParams());
        }

        const iframeEl = this.createBasicIframe();
        this.append(iframeEl);

        // Set focus for a11y
        iframeEl.focus();
    }

    createBasicIframe(){
        const iframeEl = document.createElement('iframe');
        iframeEl.width = 560;
        iframeEl.height = 315;
        // No encoding necessary as [title] is safe. https://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#:~:text=Safe%20HTML%20Attributes%20include
        iframeEl.title = this.playLabel;
        iframeEl.allow = 'accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture';
        iframeEl.allowFullscreen = true;
        // AFAIK, the encoding here isn't necessary for XSS, but we'll do it only because this is a URL
        // https://stackoverflow.com/q/64959723/89484
        iframeEl.src = `https://www.youtube-nocookie.com/embed/${encodeURIComponent(this.videoId)}?${this.getParams().toString()}`;
        return iframeEl;
    }

    /**
     * In the spirit of the `lowsrc` attribute and progressive JPEGs, we'll upgrade the reliable
     * poster image to a higher resolution one, if it's available.
     * Interestingly this sddefault webp is often smaller in filesize, but we will still attempt it second
     * because getting _an_ image in front of the user if our first priority.
     *
     * See https://github.com/paulirish/lite-youtube-embed/blob/master/youtube-thumbnail-urls.md for more details
     */
    upgradePosterImage() {
         // Defer to reduce network contention.
        setTimeout(() => {
            const webpUrl = `https://i.ytimg.com/vi_webp/${this.videoId}/sddefault.webp`;
            const img = new Image();
            img.fetchPriority = 'low'; // low priority to reduce network contention
            img.referrerpolicy = 'origin'; // Not 100% sure it's needed, but https://github.com/ampproject/amphtml/pull/3940
            img.src = webpUrl;
            img.onload = e => {
                // A pretty ugly hack since onerror won't fire on YouTube image 404. This is (probably) due to
                // Youtube's style of returning data even with a 404 status. That data is a 120x90 placeholder image.
                // ‚Ä¶ per "annoying yt 404 behavior" in the .md
                const noAvailablePoster = e.target.naturalHeight == 90 && e.target.naturalWidth == 120;
                if (noAvailablePoster) return;

                this.style.backgroundImage = `url("${webpUrl}")`;
            }
        }, 100);
    }
}
// Register custom element
customElements.define('lite-youtube', LiteYTEmbed);

			const style = document.head.appendChild(document.createElement('style'));
style.textContent = /*css*/`

  lite-vimeo {
    aspect-ratio: 16 / 9;
    background-color: #000;
    position: relative;
    display: block;
    contain: content;
    background-position: center center;
    background-size: cover;
    cursor: pointer;
  }

  lite-vimeo > iframe {
    width: 100%;
    height: 100%;
    position: absolute;
    top: 0;
    left: 0;
    border: 0;
  }

  lite-vimeo > .ltv-playbtn {
    font-size: 10px;
    padding: 0;
    width: 6.5em;
    height: 4em;
    background: rgba(23, 35, 34, .75);
    z-index: 1;
    opacity: .8;
    border-radius: .5em;
    transition: opacity .2s ease-out, background .2s ease-out;
    outline: 0;
    border: 0;
    cursor: pointer;
  }

  lite-vimeo:hover > .ltv-playbtn {
    background-color: rgb(0, 173, 239);
    opacity: 1;
  }

  /* play button triangle */
  lite-vimeo > .ltv-playbtn::before {
    content: '';
    border-style: solid;
    border-width: 10px 0 10px 20px;
    border-color: transparent transparent transparent #fff;
  }

  lite-vimeo > .ltv-playbtn,
  lite-vimeo > .ltv-playbtn::before {
    position: absolute;
    top: 50%;
    left: 50%;
    transform: translate3d(-50%, -50%, 0);
  }

  /* Post-click styles */
  lite-vimeo.ltv-activated {
    cursor: unset;
  }

  lite-vimeo.ltv-activated::before,
  lite-vimeo.ltv-activated > .ltv-playbtn {
    opacity: 0;
    pointer-events: none;
  }
`;

/**
 * Ported from https://github.com/paulirish/lite-youtube-embed
 *
 * A lightweight vimeo embed. Still should feel the same to the user, just MUCH faster to initialize and paint.
 *
 * Thx to these as the inspiration
 *   https://storage.googleapis.com/amp-vs-non-amp/youtube-lazy.html
 *   https://autoplay-youtube-player.glitch.me/
 *
 * Once built it, I also found these:
 *   https://github.com/ampproject/amphtml/blob/master/extensions/amp-youtube (üëçüëç)
 *   https://github.com/Daugilas/lazyYT
 *   https://github.com/vb/lazyframe
 */
class LiteVimeo extends (globalThis.HTMLElement ?? class {}) {
  /**
   * Begin pre-connecting to warm up the iframe load
   * Since the embed's network requests load within its iframe,
   *   preload/prefetch'ing them outside the iframe will only cause double-downloads.
   * So, the best we can do is warm up a few connections to origins that are in the critical path.
   *
   * Maybe `<link rel=preload as=document>` would work, but it's unsupported: http://crbug.com/593267
   * But TBH, I don't think it'll happen soon with Site Isolation and split caches adding serious complexity.
   */
  static _warmConnections() {
    if (LiteVimeo.preconnected) return;
    LiteVimeo.preconnected = true;

    // The iframe document and most of its subresources come right off player.vimeo.com
    addPrefetch('preconnect', 'https://player.vimeo.com');
    // Images
    addPrefetch('preconnect', 'https://i.vimeocdn.com');
    // Files .js, .css
    addPrefetch('preconnect', 'https://f.vimeocdn.com');
    // Metrics
    addPrefetch('preconnect', 'https://fresnel.vimeocdn.com');
  }

  connectedCallback() {
    this.videoId = this.getAttribute('videoid');

    /**
     * Lo, the vimeo placeholder image!  (aka the thumbnail, poster image, etc)
     * We have to use the Vimeo API.
     */
    let { width, height } = getThumbnailDimensions(this.getBoundingClientRect());
    let devicePixelRatio = window.devicePixelRatio || 1;
    if (devicePixelRatio >= 2) devicePixelRatio *= .75;
    width = Math.round(width * devicePixelRatio);
    height = Math.round(height * devicePixelRatio);

    fetch(`https://vimeo.com/api/v2/video/${this.videoId}.json`)
      .then(response => response.json())
      .then(data => {
        let thumbnailUrl = data[0].thumbnail_large;
        thumbnailUrl = thumbnailUrl.replace(/-d_[\dx]+$/i, `-d_${width}x${height}`);
        this.style.backgroundImage = `url("${thumbnailUrl}")`;
      });

    let playBtnEl = this.querySelector('.ltv-playbtn');
    // A label for the button takes priority over a [playlabel] attribute on the custom-element
    this.playLabel = (playBtnEl && playBtnEl.textContent.trim()) || this.getAttribute('playlabel') || 'Play video';

    if (!playBtnEl) {
      playBtnEl = document.createElement('button');
      playBtnEl.type = 'button';
      playBtnEl.setAttribute('aria-label', this.playLabel);
      playBtnEl.classList.add('ltv-playbtn');
      this.append(playBtnEl);
    }
    playBtnEl.removeAttribute('href');

    // On hover (or tap), warm up the TCP connections we're (likely) about to use.
    this.addEventListener('pointerover', LiteVimeo._warmConnections, {
      once: true
    });

    // Once the user clicks, add the real iframe and drop our play button
    // TODO: In the future we could be like amp-youtube and silently swap in the iframe during idle time
    //   We'd want to only do this for in-viewport or near-viewport ones: https://github.com/ampproject/amphtml/pull/5003
    this.addEventListener('click', this.addIframe);
  }

  addIframe() {
    if (this.classList.contains('ltv-activated')) return;
    this.classList.add('ltv-activated');

    const iframeEl = document.createElement('iframe');
    iframeEl.width = 640;
    iframeEl.height = 360;
    // No encoding necessary as [title] is safe. https://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#:~:text=Safe%20HTML%20Attributes%20include
    iframeEl.title = this.playLabel;
    iframeEl.allow = 'accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture';
    // AFAIK, the encoding here isn't necessary for XSS, but we'll do it only because this is a URL
    // https://stackoverflow.com/q/64959723/89484
    iframeEl.src = `https://player.vimeo.com/video/${encodeURIComponent(this.videoId)}?autoplay=1`;
    this.append(iframeEl);

    // Set focus for a11y
    iframeEl.addEventListener('load', iframeEl.focus, { once: true });
  }
}

if (globalThis.customElements && !globalThis.customElements.get('lite-vimeo')) {
  globalThis.customElements.define('lite-vimeo', LiteVimeo);
}

/**
 * Add a <link rel={preload | preconnect} ...> to the head
 */
function addPrefetch(kind, url, as) {
  const linkElem = document.createElement('link');
  linkElem.rel = kind;
  linkElem.href = url;
  if (as) {
    linkElem.as = as;
  }
  linkElem.crossorigin = true;
  document.head.append(linkElem);
}

/**
 * Get the thumbnail dimensions to use for a given player size.
 *
 * @param {Object} options
 * @param {number} options.width The width of the player
 * @param {number} options.height The height of the player
 * @return {Object} The width and height
 */
function getThumbnailDimensions({ width, height }) {
  let roundedWidth = width;
  let roundedHeight = height;

  // If the original width is a multiple of 320 then we should
  // not round up. This is to keep the native image dimensions
  // so that they match up with the actual frames from the video.
  //
  // For example 640x360, 960x540, 1280x720, 1920x1080
  //
  // Round up to nearest 100 px to improve cacheability at the
  // CDN. For example, any width between 601 pixels and 699
  // pixels will render the thumbnail at 700 pixels width.
  if (roundedWidth % 320 !== 0) {
    roundedWidth = Math.ceil(width / 100) * 100;
    roundedHeight = Math.round((roundedWidth / width) * height);
  }

  return {
    width: roundedWidth,
    height: roundedHeight
  };
}
</script>