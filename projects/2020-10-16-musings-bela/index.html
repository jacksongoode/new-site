<!doctype html>
<html lang="en" class="no-js">
	<script>document.documentElement.classList.remove('no-js');</script>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
		<title>Musings with Bela</title>
		<meta name="description" content="A tale of accelerometers, knobs, an EEG and the attempt to tame sound with my mind.">
		<meta name="generator" content="Eleventy v3.0.0">

		
		<link rel="icon" href="/icon/favicons/favicon.ico" sizes="32x32">
		<link rel="icon" href="/icon/favicons/icon.svg" type="image/svg+xml">
		<link rel="apple-touch-icon" href="/icon/favicons/apple-touch-icon.png">
		<link rel="manifest" href="/icon/favicons/manifest.webmanifest">

		<link rel="preload" as="font" href="/font/Switzer-Variable.subset.woff2" crossorigin="">
		<link rel="preload" as="font" href="/font/Rag-Regular.subset.woff2" crossorigin="">
		<link rel="alternate" href="/feed/feed.xml" type="application/atom+xml" title="Jackson">
		<link rel="alternate" href="/feed/feed.json" type="application/json" title="Jackson">
		<style>
			/*
  Josh's Custom CSS Reset
  https://www.joshwcomeau.com/css/custom-css-reset/
*/
*,
*::before,
*::after {
	box-sizing: border-box;
}
* {
	line-height: calc(1em + 0.725rem);
	margin: 0;
}
body {
	-webkit-font-smoothing: antialiased;
}
img,
picture,
video,
canvas,
svg {
	display: block;
	max-width: 100%;
}
input,
button,
textarea,
select {
	font: inherit;
}
p,
h1,
h2,
h3,
h4,
h5,
h6 {
	overflow-wrap: break-word;
	margin: revert;
}
#root,
#__next {
	isolation: isolate;
}

		:root {
	--color-bg: white;
	--color-gray-20: #333333;
	--color-gray-50: #7f7f7f;
	--color-gray-90: #e5e5e5;
	--font-family: "Rag", -apple-system, system-ui, sans-serif;
	--font-family-monospace: Consolas, Menlo, Monaco, Andale Mono WT, Andale Mono,
		Lucida Console, Lucida Sans Typewriter, DejaVu Sans Mono,
		Bitstream Vera Sans Mono, Liberation Mono, Nimbus Mono L, Courier New,
		Courier, monospace;
	--syntax-tab-size: 2;
	--noise-img: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 600 600'%3E%3Cfilter id='a'%3E%3CfeTurbulence type='fractalNoise' baseFrequency='.65' numOctaves='3' stitchTiles='stitch'/%3E%3C/filter%3E%3Crect width='100%25' height='100%25' filter='url(%23a)'/%3E%3C/svg%3E");
	--noise-opacity: 0.2;
	/* Josh Comeau shadows */
	--shadow-color: 0deg 0% 0%;
	--shadow-elevation-low: 0px 0.2px 0.2px hsl(var(--shadow-color) / 0.16),
		0.1px 0.8px 0.8px -3px hsl(var(--shadow-color) / 0.13);
	--shadow-elevation-medium: 0px 0.2px 0.2px hsl(var(--shadow-color) / 0.15),
		0.1px 1px 1.1px -1.5px hsl(var(--shadow-color) / 0.13),
		0.3px 4.2px 4.4px -3px hsl(var(--shadow-color) / 0.11);
	--shadow-elevation-high: 0px 0.2px 0.2px hsl(var(--shadow-color) / 0.14),
		0.1px 1.3px 1.4px -0.6px hsl(var(--shadow-color) / 0.13),
		0.2px 2.8px 2.9px -1.2px hsl(var(--shadow-color) / 0.12),
		0.5px 5.7px 6px -1.8px hsl(var(--shadow-color) / 0.11),
		0.9px 10.9px 11.5px -2.4px hsl(var(--shadow-color) / 0.11),
		1.5px 19.3px 20.3px -3px hsl(var(--shadow-color) / 0.1);
	--nav-height: 4rem; /* Default height to lower for header*/
	color-scheme: light dark;
}

/* Both for system and user preference */
:root[data-theme="dark"],
.dark-mode {
	--color-bg: black;
	--color-gray-20: #cccccc;
	--color-gray-50: #808080;
	--color-gray-90: #1a1a1a;
	--noise-opacity: 0.1;
	color-scheme: dark;
}

@font-face {
	font-weight: 500;
	src: url("/font/Switzer-Variable.subset.woff2") format("woff2");
	font-family: "Switzer";
	font-display: swap;
	/* font-variation-settings: "wght" 400; */
}
@font-face {
	font-style: normal italic;
	font-weight: 400;
	src:
		url("/font/Rag-Regular.subset.woff2") format("woff2"),
		url("/font/Rag-Italic.subset.woff2") format("woff2"),
		url("/font/Rag-Bold.subset.woff2") format("woff2"),
		url("/font/Rag-BoldItalic.subset.woff2") format("woff2");
	font-family: "Rag";
	font-display: swap;
}

/* Only set the overflow to the root */
html {
	contain: paint;
}
html,
body {
	padding: 0;
	background-color: Canvas;
	background-color: transparent;
	color: CanvasText;
	font-family: var(--font-family);
}

body {
	display: flex;
	flex-direction: row;
	min-height: 100dvh;
	width: 100%;
	max-width: calc(40rem + 200px + 2rem);
	margin: 0 auto;
	padding: 1rem;
}

.site-header {
	position: sticky;
	top: 0;
	align-self: flex-start;
	width: 200px;
	flex-shrink: 0;
	padding: 1rem;
}

main {
	width: 100%;
	max-width: 40rem;
	padding: 1rem;

	& h1:first-child,
	& h2:first-child,
	& h3:first-child {
		margin-top: 0;
	}

	/* Add a margin for when chat bubble is absolute */
	&:where(.chat-active) {
		margin-top: 3rem;
	}
}

/* Typography */
h1,
h2,
h3 {
	margin-top: 1.5rem;
	margin-bottom: 1rem;
}

h1,
h2,
h3,
.letter {
	text-wrap: balance;
	width: fit-content;
	font-family: "Switzer";
}

/* https://www.a11yproject.com/posts/how-to-hide-content/ */
.visually-hidden {
	clip: rect(0 0 0 0);
	position: absolute;
	width: 1px;
	height: 1px;
	overflow: hidden;
	white-space: nowrap;
	clip-path: inset(50%);
}

p:last-child {
	margin-bottom: 0;
}

/* Post navigation */
.post-nav {
	display: flex;
	flex-direction: row;
	justify-content: space-between;
	align-items: center;
	margin-top: 1rem;
}

.post-nav a {
	display: flex;
	align-items: center;
	text-decoration: none;
	color: var(--color-gray-20);
	max-width: 100%;
}

.post-nav:has(.post-nav-prev):has(.post-nav-next) a {
	max-width: calc(50% - 1rem);
}

.post-nav-prev {
	margin-right: auto;
}

.post-nav-next {
	margin-left: auto;
}

.post-nav-title {
	overflow: hidden;
	white-space: nowrap;
	text-overflow: ellipsis;
}

.post-nav-arrow {
	flex-shrink: 0;
	padding: 0 0.25rem;
}

.post-nav-divider {
	padding: 0 0.5rem;
	color: var(--color-gray-50);
}

table {
	margin: 1rem 0;
}
table td,
table th {
	padding-right: 1rem;
}

pre {
	border-radius: 0.25rem;
	box-shadow: var(--shadow-elevation-low);
}
pre,
code {
	font-family: var(--font-family-monospace);
}
pre:not([class*="language-"]) {
	-moz-tab-size: var(--syntax-tab-size);
	-o-tab-size: var(--syntax-tab-size);
	-webkit-hyphens: none;
	-ms-hyphens: none;
	margin: 0.5rem 0;
	line-height: 1.375; /* 22px /16 */
	hyphens: none;
	direction: ltr;
	text-align: left;
	white-space: pre;
	word-break: normal;
	word-spacing: normal;
	tab-size: var(--syntax-tab-size);
}
code {
	word-break: break-all;
}

/* Header */
.home-link {
	margin-right: 2rem;
	font-weight: 700;
	font-size: 1rem; /* 16px /16 */
}
.home-link:link:not(:hover) {
	text-decoration: none;
}

/* Nav */
nav {
	position: relative;
	width: 100%;
	list-style: none;
}
.nav-item {
	display: inline-block;
	padding: 0.25rem 0;
}
.nav-item a[href]:not(:hover) {
	text-decoration: none;
}
.nav a[href][aria-current="page"] {
	text-decoration: underline;
}

/* Posts list */
.postlist {
	padding: 0;
	list-style: none;
}

/* Each item in a po */
.postlist-item {
	display: flex;
	position: relative;
	flex-wrap: wrap;
	align-items: baseline;
	margin-bottom: 1rem;
	padding-left: 1.5rem; /* Add left padding to make room for the arrow */

	&::before {
		position: absolute;
		top: 0.2rem;
		left: 0;
		margin-right: 0.5rem;
		transform: scale(1);
		content: "\2192"; /* Default to arrow */
		color: var(--color-gray-20);
		filter: saturate(100%);
		transition: all 0.5s ease-out;
	}

	&[data-emoji]::before {
		content: attr(data-emoji);
	}

	&:hover::before,
	&:focus-within::before {
		animation: pulseSat 2s linear infinite;
	}

	&:not(:hover)::before {
		transform: scale(1);
		animation: none;
		filter: saturate(100%);
	}

	.postlist-date::after {
		visibility: hidden;
		position: absolute;
		max-width: calc(100% - 12rem);
		padding-left: 1rem;
		overflow: hidden;
		content: attr(data-tooltip);
		color: var(--color-gray-20);
		text-overflow: ellipsis;
		white-space: nowrap;
		opacity: 0;
		transition:
			opacity 0.3s ease,
			visibility 0.3s ease;
	}

	&:has(.postlist-link:hover) .postlist-date::after {
		visibility: visible;
		opacity: 1;
	}

	&-active .postlist-link {
		font-weight: bold;
	}
}

@keyframes pulseSat {
	0%,
	50%,
	100% {
		transform: scale(1);
		filter: saturate(100%);
	}
	25% {
		transform: scale(0.8);
		filter: saturate(50%);
	}
	75% {
		transform: scale(1.2);
		filter: saturate(150%);
	}
}
.postlist-date {
	color: var(--color-gray-20);
	font-size: 0.8125rem; /* 13px /16 */
	word-spacing: -0.5px;
}
.postlist-link {
	flex-basis: 100%;
	font-weight: 700;
	font-size: 1.1875rem; /* 19px /16 */
	text-decoration-thickness: 1px;
	text-underline-position: from-font;
	text-underline-offset: 0;
}

/* Tags */
.post-tag {
	display: inline-flex;
	align-items: center;
	justify-content: center;
	font-style: italic;
	text-transform: capitalize;
}
.postlist-item > .post-tag {
	align-self: center;
}

/* Tags list */
.post-metadata {
	display: inline-flex;
	flex-wrap: wrap;
	margin: 0;
	padding: 0;
	gap: 0.5rem;
	list-style: none;
}
.post-metadata time {
	margin-right: 1rem;
}

/* Direct Links / Markdown Headers */
.header-anchor {
	margin-left: 0.1rem;
	font-style: normal;
	text-decoration: none;
}
a[href].header-anchor,
a[href].header-anchor:visited {
	color: transparent;
}
a[href].header-anchor:focus,
a[href].header-anchor:hover {
	text-decoration: underline;
}
a[href].header-anchor:focus,
:hover > a[href].header-anchor {
	color: #aaa;
}

h2 + .header-anchor {
	font-size: 1.5rem;
}

/* Figures */
figure {
	margin: 1rem 0;
}
figure > * {
	max-width: 100%;
	margin: 0 auto;
}
/* All images & videos should be in a figure */
figure :first-child {
	border-radius: 0.25rem;
	box-shadow: var(--shadow-elevation-low);
}

figcaption {
	margin-top: 0.5rem;
	color: var(--color-gray-50);
	text-align: center;
}

blockquote {
	padding-left: 1rem;
	border-left: 2px solid ButtonFace;
}

/* Talk bubble styling */
.nav-phrase {
	display: none;
	width: 100%;
	padding: 0 0.5rem;
	cursor: text;
}

.nav-bubble {
	display: flex;
	position: absolute;
	align-items: center;
	justify-content: space-between;
	width: calc(100% - 2.5rem);
	margin: 0;
	padding: calc(0.25rem - 1px);
	transform: translateY(calc(var(--item-top) - 12px));
	border: 1px solid var(--color-gray-90);
	border-radius: 0.25rem;
	background: ButtonFace;
	transition: transform 0.3s ease;

	&:before,
	&:after {
		position: absolute;
		top: 10px;
		right: -7.5px;
		width: 0;
		height: 0;
		border: 8px solid transparent;
		border-right: 0;
		content: "";
	}

	&:before {
		right: -9px;
		border-left-color: var(--color-gray-90);
	}

	&:after {
		border-left-color: ButtonFace;
	}

	/* Reset position when chat is active */
	&:where(.chat-active) {
		transform: none;
	}
}

/* Talk bubble movement */
header {
	/* We need to add 1 to the active item to account for the first item */
	--item-top: calc(12px + var(--nav-item-active, 1) * var(--nav-item-height));
	--nav-item-height: 36px;
	z-index: 1; /* Ensure the header is above other elements */

	display: flex;
	flex-direction: column;
	align-items: flex-end;
	justify-content: flex-start;
	width: 200px;
	padding: 1rem;

	&:not(:has(+ .chat-active)) {
		&:has(.nav-item:nth-child(n):hover) {
			--n: var(--n);
			--item-top: calc(12px + (var(--n) - 1) * var(--nav-item-height));
		}
		&:has(.nav-item:nth-child(1):hover) {
			--n: 1;
		}
		&:has(.nav-item:nth-child(2):hover) {
			--n: 2;
		}
		&:has(.nav-item:nth-child(3):hover) {
			--n: 3;
		}
		&:has(.nav-item:nth-child(4):hover) {
			--n: 4;
		}
		&:has(.nav-item:nth-child(5):hover) {
			--n: 5;
		}
	}
}

.side-nav {
	display: flex;
	justify-content: center;
	width: 100%;
	padding-right: 2rem;
}

.nav-list {
	display: flex;
	z-index: 1;
	flex-direction: column;
	width: 100%;
	margin: 0;
	padding-right: 1rem;
	padding-inline-start: 0;
	list-style: none;
	text-align: right;
}

.theme-toggle {
	position: relative;
	right: -2.25rem;
	align-self: flex-start;
	margin-left: auto;
	transition: transform 0.3s ease;
}

#chat-toggle {
	cursor: pointer;
}

/* Dark mode toggle styles */
#dark-mode-toggle {
	display: none;
}

#dark-mode-toggle + label {
	border: none;
	background: none;
	font-size: 1rem;
	cursor: pointer;
}

#dark-mode-toggle + label::before {
	content: "🐓";
}

#dark-mode-toggle:checked + label::before {
	content: "🐸";
}

@media (prefers-color-scheme: dark) {
	#dark-mode-toggle:not(:checked) + label::before {
		content: "🐓";
	}
	#dark-mode-toggle:checked + label::before {
		content: "🐸";
	}
}

:root:has(#dark-mode-toggle:checked) {
	color-scheme: dark;
}

:root:has(#dark-mode-toggle:not(:checked)) {
	color-scheme: light;
}

/* Chat bubble related */
#user-input {
	width: 100%;
	/* Mozilla? */
	padding: 0;
	border: none;
	outline: none;
	background: none;
	color: inherit;
	font-size: inherit;
	font-family: inherit;
}

#user-input::placeholder,
.waiting {
	color: var(--color-gray-50);
	opacity: 0.7;
}

#chat-form {
	width: 100%;
}

#chat-form button {
	display: none;
}

@keyframes ellipsis {
	0% {
		content: ".";
	}
	33% {
		content: "..";
	}
	66% {
		content: "...";
	}
}

.waiting::after {
	display: inline-block;
	width: 1rem;
	content: ".";
	text-align: left;
	animation: ellipsis 1s infinite;
}

/* Chat reset */
.chat-reset {
	display: none;
	position: relative;
	align-self: flex-start;
	padding: 0 0.5rem;
	border: none;
	background: none;
	color: gray;
	cursor: pointer;
}

/* Add shadow to nav bubble */
.nav-bubble {
	box-shadow: var(--shadow-elevation-low);
}
.nav-bubble.chat-active {
	position: absolute;
	box-shadow: var(--shadow-elevation-medium);
}

.nav-bubble.chat-active .chat-reset {
	display: inline-block;
}

/* Only do nav switch on wide screens */
@media (min-width: 840px) {
	.nav-bubble {
		&:where(.chat-active) {
			/* left: calc(50% + 200px); */
			/* width: calc(640px - 200px); */
			left: calc(200px);
			width: calc(640px - 4.5rem);
		}

		&:where(.chat-active) > * {
			display: inline-block;
		}
	}
}

/* For mobile view */
@media (max-width: 839px) {
	/* Switch side nav off */
	.side-nav {
		display: none;
	}

	/* Mobile */
	.nav-phrase {
		display: inline-block;
	}

	body {
		flex-direction: column; /* Stack header and main content on narrow screens */
		max-width: 40rem;
		padding: 0;
	}

	main {
		max-width: none;
	}

	.site-header {
		position: relative;
		width: 100%; /* Full width on narrow screens */
		max-width: 640px;
		height: auto;
		padding-bottom: 0;
		gap: 1rem 0.5rem;
	}

	/* Mobile-specific nav bubble styles */
	.nav-bubble {
		position: relative;
		left: initial;
		transform: none;
	}

	header {
		position: relative;
		height: auto;
		width: 100%;
		align-items: flex-start;
	}
}

/* Util */
.line-clamp {
	-webkit-box-orient: vertical;
	display: -webkit-box;
	line-clamp: 2;
	-webkit-line-clamp: 2;
	overflow: hidden;
}

.noise-container {
	z-index: -1;
	position: fixed;
	top: 0;
	left: 0;
	width: 100%;
	height: 100%;
	background-image: var(--noise-img);
	background-size: 182px;
	background-repeat: repeat;
	opacity: var(--noise-opacity);
	pointer-events: none;
}

/* Spotify widget */
.spotify-widget img {
	display: inline-block;
	border-radius: 0.25rem;
	box-shadow: var(--shadow-elevation-low);
}

/* Sidebar progress bar */
.progress-bar {
	position: fixed;
	top: 0;
	left: 0;
	width: 0.5rem;
	height: 100vh;
	transform: scaleY(0);
	transform-origin: 0 0;
	background-color: var(--color-gray-50);
}

@supports (animation-timeline: scroll()) {
	html {
		-ms-overflow-style: none; /* Internet Explorer 10+ */
		scrollbar-width: none; /* Firefox */
	}

	html::-webkit-scrollbar {
		display: none; /* Chrome, Safari, and Opera */
		width: 0;
		height: 0;
	}

	.progress-bar {
		animation-timeline: scroll(root block);
		animation-range: entry 0% cover 100%;
		animation: grow-progress linear;
	}

	@keyframes grow-progress {
		to {
			transform: scaleY(1);
		}
	}
}

/* Citation */
.citation {
	margin-bottom: 1rem;
	padding-left: 2rem;
	text-indent: -2rem;
}

.citation p {
	margin: 0;
}

/* Search results */
#search-results {
	max-height: 50vh;
	overflow-y: auto;
}
#search-results:has(.search-result) {
	margin-top: 0.25rem;
	border-top: 1px solid var(--color-gray-90);
}

.search-result {
	--border-width: 0px;
	display: block;
	padding: 0.5rem 1rem;
	border-bottom: 1px solid var(--color-gray-90);
	background: linear-gradient(var(--color-gray-50), var(--color-gray-50))
		left/var(--border-width) 100% no-repeat;
	color: inherit;
	text-decoration: none;
	transition: 0.3s ease;
	transition-property: background-size, background-color;
}

.search-result:hover {
	--border-width: 3px;
	background-color: var(--color-gray-90);
}

.search-result a {
	color: var(--color-gray-20);
	font-weight: bold;
	text-decoration: none;
}

.search-result p {
	margin: 0;
	color: var(--color-gray-50);
}

/* Wave divider */
#post-title {
	margin-bottom: 0.5rem;
}

:root {
	--wave-width: 30px;
	--wave-height: 10px;
}

.wave-divider {
	width: 100%;
	height: var(--wave-height);
	margin: 2rem 0;
	/* margin-top: 0.3rem;
	margin-bottom: 1rem; */
	background-color: var(--emoji-color);

	/* Wave mask */
	--wave-mask: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='60' height='10'%3E%3Cpath d='M0 5q15-5 30 0t30 0' stroke='white' fill='none' stroke-width='1.5'/%3E%3C/svg%3E");

	/* Fade-out mask */
	--fade-mask: linear-gradient(
		to right,
		transparent,
		black 15%,
		black 85%,
		transparent
	);

	/* Combine masks */
	mask-image: var(--wave-mask), var(--fade-mask);
	mask-size:
		var(--wave-width) var(--wave-height),
		100% 100%;
	mask-repeat: repeat-x, no-repeat;
	mask-composite: intersect;

	/* For webkit browsers */
	-webkit-mask-image: var(--wave-mask), var(--fade-mask);
	-webkit-mask-size:
		var(--wave-width) var(--wave-height),
		100% 100%;
	-webkit-mask-repeat: repeat-x, no-repeat;
	-webkit-mask-composite: source-in;

	animation: wave-animation 5s linear infinite;
}

@keyframes wave-animation {
	0% {
		mask-position:
			0 0,
			0 0;
		-webkit-mask-position:
			0 0,
			0 0;
	}
	100% {
		mask-position:
			var(--wave-width) 0,
			0 0;
		-webkit-mask-position:
			var(--wave-width) 0,
			0 0;
	}
}


		
		
			/* PrismJS 1.29.0
https://prismjs.com/download.html#themes=prism-tomorrow&languages=markup+css+clike+javascript+bash+python */
code[class*=language-],pre[class*=language-]{color:#ccc;background:0 0;font-family:Consolas,Monaco,'Andale Mono','Ubuntu Mono',monospace;font-size:1em;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto}:not(pre)>code[class*=language-],pre[class*=language-]{background:#2d2d2d}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal}.token.block-comment,.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#999}.token.punctuation{color:#ccc}.token.attr-name,.token.deleted,.token.namespace,.token.tag{color:#e2777a}.token.function-name{color:#6196cc}.token.boolean,.token.function,.token.number{color:#f08d49}.token.class-name,.token.constant,.token.property,.token.symbol{color:#f8c555}.token.atrule,.token.builtin,.token.important,.token.keyword,.token.selector{color:#cc99cd}.token.attr-value,.token.char,.token.regex,.token.string,.token.variable{color:#7ec699}.token.entity,.token.operator,.token.url{color:#67cdcc}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}.token.inserted{color:green}

			lite-youtube {
    background-color: #000;
    position: relative;
    display: block;
    contain: content;
    background-position: center center;
    background-size: cover;
    cursor: pointer;
    max-width: 720px;
}

/* gradient */
lite-youtube::before {
    content: attr(data-title);
    display: block;
    position: absolute;
    top: 0;
    /* Pixel-perfect port of YT's gradient PNG, using https://github.com/bluesmoon/pngtocss plus optimizations */
    background-image: linear-gradient(180deg, rgb(0 0 0 / 67%) 0%, rgb(0 0 0 / 54%) 14%, rgb(0 0 0 / 15%) 54%, rgb(0 0 0 / 5%) 72%, rgb(0 0 0 / 0%) 94%);
    height: 99px;
    width: 100%;
    font-family: "YouTube Noto",Roboto,Arial,Helvetica,sans-serif;
    color: hsl(0deg 0% 93.33%);
    text-shadow: 0 0 2px rgba(0,0,0,.5);
    font-size: 18px;
    padding: 25px 20px;
    overflow: hidden;
    white-space: nowrap;
    text-overflow: ellipsis;
    box-sizing: border-box;
}

lite-youtube:hover::before {
    color: white;
}

/* responsive iframe with a 16:9 aspect ratio
    thanks https://css-tricks.com/responsive-iframes/
*/
lite-youtube::after {
    content: "";
    display: block;
    padding-bottom: calc(100% / (16 / 9));
}
lite-youtube > iframe {
    width: 100%;
    height: 100%;
    position: absolute;
    top: 0;
    left: 0;
    border: 0;
}

/* play button */
lite-youtube > .lty-playbtn {
    display: block;
    /* Make the button element cover the whole area for a large hover/click target… */
    width: 100%;
    height: 100%;
    /* …but visually it's still the same size */
    background: no-repeat center/68px 48px;
    /* YT's actual play button svg */
    background-image: url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 68 48"><path d="M66.52 7.74c-.78-2.93-2.49-5.41-5.42-6.19C55.79.13 34 0 34 0S12.21.13 6.9 1.55c-2.93.78-4.63 3.26-5.42 6.19C.06 13.05 0 24 0 24s.06 10.95 1.48 16.26c.78 2.93 2.49 5.41 5.42 6.19C12.21 47.87 34 48 34 48s21.79-.13 27.1-1.55c2.93-.78 4.64-3.26 5.42-6.19C67.94 34.95 68 24 68 24s-.06-10.95-1.48-16.26z" fill="red"/><path d="M45 24 27 14v20" fill="white"/></svg>');
    position: absolute;
    cursor: pointer;
    z-index: 1;
    filter: grayscale(100%);
    transition: filter .1s cubic-bezier(0, 0, 0.2, 1);
    border: 0;
}

lite-youtube:hover > .lty-playbtn,
lite-youtube .lty-playbtn:focus {
    filter: none;
}

/* Post-click styles */
lite-youtube.lyt-activated {
    cursor: unset;
}
lite-youtube.lyt-activated::before,
lite-youtube.lyt-activated > .lty-playbtn {
    opacity: 0;
    pointer-events: none;
}

.lyt-visually-hidden {
    clip: rect(0 0 0 0);
    clip-path: inset(50%);
    height: 1px;
    overflow: hidden;
    position: absolute;
    white-space: nowrap;
    width: 1px;
  }
		</style>
	</head>

	<body style="--nav-item-active: 1;">
		<div class="noise-container"></div>
		<a href="#skip" class="visually-hidden">Skip to main content</a>

		<header class="site-header">
			<nav>
				<h2 class="visually-hidden">Top level navigation menu</h2>
				<div class="nav-bubble">
    <button id="chat-reset" class="chat-reset" aria-label="Reset chat">↺</button>
    <div id="navPhrase" class="nav-phrase">
        
            
            <a href="/" style="text-decoration: none;">Home</a>&emsp;<a href="/projects/" style="text-decoration: none;">Projects</a>&emsp;<a href="/blog/" style="text-decoration: none;">Blog</a>&emsp;<a href="/about/" style="text-decoration: none;">About Me</a>
        
    </div>
    <form method="post" id="theme-form" class="theme-toggle">
        <input type="checkbox" id="dark-mode-toggle" name="theme" value="dark" aria-label="Toggle dark mode">
        <label for="dark-mode-toggle"></label>
    </form>
</div>
				<div class="side-nav">
					<ul class="nav-list">
						<li id="chat-toggle" class="nav-item">Welcome!</li>
							<li class="nav-item">
								<a href="/">Home</a>
							</li>
							<li class="nav-item">
								<a href="/projects/">Projects</a>
							</li>
							<li class="nav-item">
								<a href="/blog/">Blog</a>
							</li>
							<li class="nav-item">
								<a href="/about/">About Me</a>
							</li>
					</ul>
				</div>
			</nav>
		</header>

		<main id="skip">
			


<div class="progress-bar"></div>

<article class="post">
  <h1 id="post-title">
    Musings with Bela&ensp;🧠
  </h1>

  <ul class="post-metadata">
    <li>
      <time datetime="2020-10-16">16 October 2020</time>
    </li>
      <li>
        <a href="/tags/projects/" class="post-tag">projects</a>
      </li>
  </ul>

  <div class="wave-divider" style="--emoji-color: #f59999;"></div>

  <p>In an effort to explore the wild world of interactive music systems, I decided to work with a <a href="https://choosemuse.com/">portable EEG reader</a> and a <a href="https://bela.io/">Bela</a> coupled with an accelerometer and potentiometers. Little did I know how much of a challenge it would be to join both software and hardware within an interactive package.</p>
<h2 id="inspiration" tabindex="-1">Inspiration <a class="header-anchor" href="#inspiration">#</a></h2>
<p>Coming from a undergraduate degree in cognitive science, I've always wanted to work with (read hack) an <a href="https://en.wikipedia.org/wiki/Electroencephalography">electroencephalogram</a> (EEG) for some kind of artistic performance or instrument. While I have worked with a more traditional systems that require head-caps and conductive gel, I have never had the opportunity to test out some of the many different portable systems that have come out in the last decade. After reaching out to <a href="https://arj.no">Alexander Jensenius</a>, I was able to borrow a system from a researcher at RITMO - which I'll cover later in the hardware section.</p>
<h3 id="artistic-examples" tabindex="-1">Artistic examples <a class="header-anchor" href="#artistic-examples">#</a></h3>
<p>In addition to my personal interest in finding an artistic meeting point between cog-sci and MCT, I was also inspired by a number of performances and musical systems that employed EEG technology.</p>
<p>The first of these was <a href="https://en.wikipedia.org/wiki/Alvin_Lucier">Alvin Lucier's</a> &quot;Music for Solo Performer&quot; (1965) which was a landmark piece not only for its use of an EEG but sonification generally. Lucier had mapped the voltage potential from his electrodes into low-frequency tones that were able to excite percussive instruments in front of him.</p>
<figure>
				<lite-youtube videoid="bIPU2ynqy2Y" style="background-image: url('https://i.ytimg.com/vi/bIPU2ynqy2Y/hqdefault.jpg');" <p="">data-title=&quot;Alvin Lucier's Music for Solo Performer (1965)&quot;
&gt;
<button type="button" class="lty-playbtn">
<span class="lyt-visually-hidden">Alvin Lucier's Music for Solo Performer (1965)</span>
</button>
</lite-youtube>
<figcaption>Alvin Lucier's Music for Solo Performer (1965)</figcaption>
</figure><p></p>
<p>The second performance that offered insights into using EEG's in a sonic environment was Ouzounian et al.'s Music for Sleeping &amp; Waking Minds (2011-2012). In their piece, they asked a group of participants to wear EEG sensors as they spent a night in a collective slumber. Over the course of the night, their brain waves (in passing through the various oscillatory states of sleep) were represented in sound and light.</p>
<figure>
				<lite-vimeo videoid="30261043" style="aspect-ratio: 16/9;">
					<div class="ltv-playbtn"></div>
				</lite-vimeo>
				<figcaption>Participants sleeping for Music for Sleeping & Waking Minds (2011-2012)</figcaption>
			</figure>
<p>In addition to these, there were a number of other interesting takes on EEG sonification such as <a href="http://graceleslie.com/MoodMixer">MoodMixer</a> (Leslie and Mullen, 2011), a collaborative installation where two participants navigate a shared musical space via EEG as represented by a 2D visual space. Another implementation comes from the <a href="https://www.researchgate.net/publication/209435991_Disembodied_and_Collaborative_Musical_Interaction_in_the_Multimodal_Brain_Orchestra">Multimodal Brain Orchestra</a> (Le Grouz et al., 2010), a collection of musicians whose sheet music was generated on the spot as a product from a reading of their collective cognitive response. And recently, <a href="https://www.youtube.com/watch?v=n0T2uB-GLc8">Chris Chafe</a> worked on sonification of seizure data recorded from EEGs, providing an illumination of hidden neural activity.</p>
<p>However, in all of these examples, it's not obvious what the sensor data is actually being mapped to - a confusing experience from both the audience as well as someone trying to find inspiration for an IMS of their own. For a much more clear framework on how one would go about building and evaluating an IMS, I turned to the literature.</p>
<h3 id="academic-support" tabindex="-1">Academic support <a class="header-anchor" href="#academic-support">#</a></h3>
<p>Two articles held my interest during the time I spent conceptualizing and designing my system, the first from Birnbaum et al. In their article Towards a Dimension Space for Musical Devices, the authors lay out a visual representation for describing aspects of IMS (Birnbaum et al., 2005). They identify 7-axes that might characterize new interactive music systems and, in parallel, provide some representative space of which to locate an author's proposal for their own IMS.</p>
<ul>
<li>Required Expertise</li>
<li>Musical Control</li>
<li>Feedback Modalities</li>
<li>Degrees of Freedom</li>
<li>Inter-actors</li>
<li>Distribution in Space</li>
<li>Role of Sound</li>
</ul>
<p>These principles were helpful as a means of comparing my proposed instrument against others but also for a class of features to focus on as I developed it. For Musings with Bela, this is how we might visualize its capacity as an instrument:</p>
<figure><img src="/img/musings-dim_space.png" alt="Musings with Bela's dimension space" loading="lazy" decoding="async"><figcaption>Musings with Bela's dimension space</figcaption></figure>
<p>The second paper, A Framework for the Evaluation of Digital Musical Instruments by O'Modhrain takes ups a similar issue with the absence of well defined lenses through which we can consider, criticize and explain a musical instrument (O'Modhrain, 2011). O'Modhrain suggest that taking the perspective of not only a musician or designer when building an IMS, but also that of an audience member or even a manufacturer. These novel perspectives force an author to consider their instrument from angles that are not typically confronted until after the instrument has been built. In both articles, it is clear that building a musical interface is a project whose treatment must be considered with others in mind.</p>
<h2 id="hardware" tabindex="-1">Hardware <a class="header-anchor" href="#hardware">#</a></h2>
<p>The device actually made use of the breadboard it was wired to as a frame to hold and rotate the device. The Bela was placed in between the accelerometer and two knobs, allowing for it to easily sit in one's hands. The idea was to keep the design uncomplicated as the EEG might require the performer to have their eyes closed.</p>
<!-- <div class="flex">
    <figure class="split-view">
        <img src="/img/musings-bela.jpg">
        <figcaption>Bela and friends</figcaption>
    </figure>
    <figure class="split-view">
        <img src="/img/musings-muse.jpg">
        <figcaption>The Muse</figcaption>
    </figure>
</div> -->
<p>A <a href="https://choosemuse.com/">Muse</a> (2016) portable eeg headband, graciously borrowed from RITMO, was another major hardware device incorporated within my IMS. I had read through my preliminary research that this device might be easily hackable. Imagine my frustration after finding out all developer resources for the device were discontinued in the last year. Unbroken, I pushed forward and ended up modifying a completely unknown Python package to finally interface with the device.</p>
<p>Nevertheless, the device's specs were quite impressive with 4 electrodes recording at 256Hz and an all-day battery life (no joke). Unfortunately, the fact that the device streamed through Bluetooth meant that my laptop would necessarily be involved (I wouldn't <em>dare</em> attempt it on the Bela (Okay, maybe if I had another week!)).</p>
<h2 id="software" tabindex="-1">Software <a class="header-anchor" href="#software">#</a></h2>
<h2 id="interpolating-between-tables-with-an-accelerometer" tabindex="-1">Interpolating between tables with an accelerometer <a class="header-anchor" href="#interpolating-between-tables-with-an-accelerometer">#</a></h2>
<figure><img src="/img/musings-tables.webp" alt="Sliding between different tables" loading="lazy" decoding="async"><figcaption>Sliding between different tables</figcaption></figure>
<p>At the core of my system was a method for interpolating between short audio grains. Audio files were read into an array of 1024 samples and these arrays were then interpolated using the external <a href="">iemmatrix</a>. More typical methods of reading through arrays would be to step through each index and read the sample, apply whatever operation you wanted and then store it. In my case, however, I wanted to tie the accelerometer to degree each sound file is interpolated into one another (via arrays) which makes it challenge to read through these arrays sequentially when the sample rate of change needs to be very fast. iemmatrix instead, allows for operations to take place on the array as a whole (like <a href="https://www.geeksforgeeks.org/vectorization-in-python/">numpy vectorization</a>) meaning this is a much more efficient method of morphing between these arrays.</p>
<figure><img src="/img/musings-intrp.png" alt="A shot of the main matrix operation sub-patch" loading="lazy" decoding="async"><figcaption>A shot of the main matrix operation sub-patch</figcaption></figure>
<p>What's cool about this is that working with sound files as tables allows you to do some non-linear transformations like interpolating between a sound and it's reverse sequence.</p>
<figure><img src="/img/musings-reverse.webp" alt="Morphing between a sound bite and its flipped image" loading="lazy" decoding="async"><figcaption>Morphing between a sound bite and its flipped image</figcaption></figure>
<p>Upon reflection, another alternative would be to get two readings, do the matrix operations, and slide between them with a [line] object. As I was looking into this, this is an external (list-abs) that allows for linear interpolation between lists. However, this might be a slightly more costly object to use - perhaps a combination of both techniques would have worked best.</p>
<p>The two physical knobs control an oscillator to read the resultant table (a morphed sound grain) into the DAC. These knobs are also read at audio-rate but the operations they control are far less complicated. In Musings with Bela, these knobs serve as tuners for the synth that can explored (sonically) by rotating the device.</p>
<h2 id="reading-arrays-and-remaining-calm" tabindex="-1">Reading arrays and remaining calm <a class="header-anchor" href="#reading-arrays-and-remaining-calm">#</a></h2>
<p>Finally, the last piece to my glorious IMS puzzle, the Muse! As I mentioned, this device was tricky, thorny, and a general struggle to work with, especially considering I had to set the Bela up as a WiFi hot-spot to pass the samples from the Muse, to my PC and then off to the Bela.</p>
<p>Another major piece of working with the Muse was actually testing to see the behavior of the electrode readings: if they were consistent, their fluctuations, and whether or not I would be able to reliably reduce the noise and relative intensity. I made a sub-patch to test for this reason, allowing me to record and playback samples from the Muse even without its connection.</p>
<figure><img src="/img/musings-eeg.webp" alt="Data from the Muse" loading="lazy" decoding="async"><figcaption>Data from the Muse</figcaption></figure>

<p>Musings with Bela takes this EEG stream and modulate the amplitude of the read table so that, in theory, a wandering, active mind would lead to a disrupted synth. The configuration was technical to say the least and, in retrospect, something I wish I had tackled earlier in the building process so I could use the EEG signals in a more complex mapping.</p>
<h2 id="reflections" tabindex="-1">Reflections <a class="header-anchor" href="#reflections">#</a></h2>
<p>Building an IMS is a whirlwind of an experience and one that is especially difficult to achieve in two weeks. Working with hardware and software turned out to double the time I expected any individual task would take. However, I feel like I had successfully built an interesting system that touched on my history with cognitive science and applied within an acousmatic environment.</p>
<p>Here is my short, final performance for MCT4045</p>
<figure>
				<lite-youtube videoid="gEq9EnWrApc" style="background-image: url('https://i.ytimg.com/vi/gEq9EnWrApc/hqdefault.jpg');" params="start=901" data-title="Musings with Bela Performance">
					<button type="button" class="lty-playbtn">
						<span class="lyt-visually-hidden">Musings with Bela Performance</span>
					</button>
				</lite-youtube>
				<figcaption>Musings with Bela Performance</figcaption>
			</figure>
<p>And my final presentation can be found below as well</p>
<figure>
    <iframe loading="lazy" src="https://slides.com/jacksongoode/musings-bela/embed" width="800" height="450" scrolling="no" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>
</figure>
<h2 id="references" tabindex="-1">References <a class="header-anchor" href="#references">#</a></h2>
<p class="citation">Birnbaum, D., et al.. (2005). <em>Towards a Dimension Space for Musical Devices</em></p>
<p class="citation">Fan, Y.-Y., & Sciotto, F. M.. (2013). <em>BioSync: An Informed Participatory Interface for Audience Dynamics and Audiovisual Content Co-Creation Using Mobile PPG and EEG</em>. NIME, pp. 248--251</p>
<p class="citation">Hamano, T., et al.. (2013). <em>Generating an Integrated Musical Expression with a Brain-Computer Interface</em>. NIME, pp. 49--54</p>
<p class="citation">Le Groux, S., et al.. (2010). <em>Disembodied and Collaborative Musical Interaction in the Multimodal Brain Orchestra</em>. NIME, pp. 309--314</p>
<p class="citation">Leslie, G., & Mullen, T. R.. (2011). <em>MoodMixer: EEG-Based Collaborative Sonification</em>. NIME, pp. 296--299</p>
<p class="citation">O'Modhrain, S.. (2011). <em>A Framework for the Evaluation of Digital Musical Instruments</em>. Computer Music Journal, vol. 35, Mar. 2011, pp. 28--42</p>
<p class="citation">Ouzounian, G., et al.. (2012). <em>To Be inside Someone Else's Dream: On Music for Sleeping & Waking Minds</em>. New Interfaces for Musical Expression (NIME 2012), pp. 1--6</p>
<p class="citation">Parvizi, J., et al.. (2018). <em>Detecting Silent Seizures by Their Sound</em>. Epilepsia, vol. 59, no. 4, pp. 877--84</p>
<p class="citation">Straebel, V., & Thoben, W.. (2014). <em>Alvin Lucier's Music for Solo Performer: Experimental Music beyond Sonification</em>. Organised Sound, vol. 19, no. 1, pp. 17--29</p>
<p class="citation">Wu, D., et al.. (2013). <em>Scale-Free Brain Quartet: Artistic Filtering of Multi-Channel Brainwave Music</em>. PloS One, vol. 8, no. 5, p. e64046</p>


  <div class="wave-divider" style="--emoji-color: #f59999;"></div>
    <nav class="post-nav">
        <a href="/projects/2020-09-20-classifying-urban-sounds/" class="post-nav-prev">
          <span class="post-nav-arrow">←</span>
          <span class="post-nav-title">Classifying Urban Sounds in a Multi-label Database</span>
        </a>
        <span class="post-nav-divider">•</span>
        <a href="/projects/2020-10-23-film-for-music/" class="post-nav-next">
          <span class="post-nav-title">Music for a Series of Scenes</span>
          <span class="post-nav-arrow">→</span>
        </a>
    </nav>
</article>
		</main>

		<footer></footer>

		<!-- This page `/projects/2020-10-16-musings-bela/` was built on 2024-10-01T23:47:10.921Z -->
	</body>
</html>
<script defer="">
	// Minimal JS for handling user preference
(function () {
    const toggle = document.getElementById('dark-mode-toggle');

    // Set initial state based on localStorage or system preference
    const storedTheme = localStorage.getItem('color-scheme');
    if (storedTheme) {
        document.documentElement.setAttribute('data-theme', storedTheme);
        toggle.checked = storedTheme === 'dark';
    }

    // Handle toggle changes
    toggle.addEventListener('change', () => {
        const newTheme = toggle.checked ? 'dark' : 'light';
        document.documentElement.setAttribute('data-theme', newTheme);
        localStorage.setItem('color-scheme', newTheme);
    });

    // const form = document.getElementById('theme-form');
    // Handle form submission (for no-JS fallback)
    // form.addEventListener('submit', (e) => {
    //     e.preventDefault();
    //     const formData = new FormData(form);
    //     fetch('/set-theme', {
    //         method: 'POST',
    //         body: formData
    //     }).then(() => {
    //         location.reload();
    //     });
    // });
})();

		// Generate a random user ID if not already stored
function getUserId() {
	return (
		localStorage.getItem("userId") ||
		localStorage.setItem(
			"userId",
			"user_" + Math.random().toString(36).slice(2, 11),
		)
	);
}

function sendMessageToWorker(message) {
	const baseUrl =
		window.location.hostname === "localhost" ||
		window.location.hostname === "127.0.0.1"
			? "http://localhost:8090"
			: "";
	const isDarkMode =
		document.documentElement.getAttribute("data-theme") === "dark";
	const animalParam = isDarkMode ? "frog" : "chicken";

	updateNavPhrase(isDarkMode ? "Ribbit" : "Cluck", true);

	// Get the body content
	const bodyContent = document.body.innerText;

	// Prepare the message with the body content
	const fullMessage = `Current page content:\n${bodyContent}\n\nUser message: ${message}`;

	fetch(
		`${baseUrl}/ai?message=${encodeURIComponent(fullMessage)}&animal=${animalParam}&userId=${getUserId()}`,
	)
		.then((response) => {
			if (!response.ok)
				throw new Error(`HTTP error! status: ${response.status}`);
			return response.body.getReader();
		})
		.then((reader) => {
			let accumulatedResponse = "";

			function readStream() {
				let buffer = "";
				reader.read().then(function processText({ done, value }) {
					if (done) {
						updateNavPhrase(accumulatedResponse, false);
						return;
					}

					buffer += new TextDecoder().decode(value);
					let newlineIndex;
					while ((newlineIndex = buffer.indexOf("\n")) !== -1) {
						const line = buffer.slice(0, newlineIndex);
						buffer = buffer.slice(newlineIndex + 1);

						if (line.startsWith("data: ")) {
							try {
								const jsonStr = line.slice(5).trim();
								if (jsonStr === "[DONE]") {
									updateNavPhrase(accumulatedResponse, false);
									return;
								}
								const data = JSON.parse(jsonStr);
								if (data.response) {
									accumulatedResponse += data.response;
									updateNavPhrase(accumulatedResponse, false);
								}
							} catch (error) {
								buffer = line + "\n" + buffer;
								break;
							}
						}
					}

					return reader.read().then(processText);
				});
			}

			readStream();
		})
		.catch((error) => {
			console.error("Fetch error:", error);
			updateNavPhrase("Sorry, something went wrong.");
		});
}

function updateNavPhrase(text, isWaiting = false) {
	const navPhrase = document.getElementById("navPhrase");
	navPhrase.textContent = text;
	navPhrase.classList.toggle("waiting", isWaiting);
	navPhrase.classList.toggle("clickable", !isWaiting && text.length > 0);
}

document.addEventListener("DOMContentLoaded", function () {
	const chatTrigger = document.getElementById("chat-toggle");
	const talkBubble = document.querySelector(".nav-bubble");
	const mainContent = document.querySelector("main");
	const navPhrase = document.getElementById("navPhrase");
	const chatReset = document.getElementById("chat-reset");
	let originalContent = navPhrase.innerHTML;

	function resetChatInterface() {
		navPhrase.innerHTML = originalContent;
		talkBubble.classList.remove("chat-active");
		mainContent.classList.remove("chat-active");
	}

	chatReset.addEventListener("click", resetChatInterface);

	function activateChatInterface() {
		navPhrase.innerHTML = `
		<form id="chat-form">
		  <input type="text" id="user-input" placeholder="Search... or say hi?">
		  <button type="submit" style="display:none;">Send</button>
		</form>
		<div id="search-results"></div>
	  `;
		document.getElementById("user-input").focus();

		const searchResults = document.getElementById("search-results");
		let pagefind;

		document
			.getElementById("user-input")
			.addEventListener("input", async function () {
				if (!pagefind) {
					pagefind = await import("/pagefind/pagefind.js");
					await pagefind.options({
						element: "#search-results",
						excerptLength: 15,
						highlightParam: "highlight",
					});
					await pagefind.init();
				}

				const query = this.value.trim();
				if (query.length > 2) {
					const search = await pagefind.search(query);
					const results = await Promise.all(
						search.results.map((r) => r.data()),
					);

					searchResults.innerHTML =
						results.length > 0
							? results
									.map(
										(result) => `
			<a href="${result.url}" class="search-result">
			  <div class="search-result-title">${result.meta.title || "Untitled"}</div>
			  <p>${result.excerpt}</p>
			</a>
		  `,
									)
									.join("")
							: "";
					talkBubble.classList.add("chat-active");
				} else {
					searchResults.innerHTML = "";
				}
			});

		document
			.getElementById("chat-form")
			.addEventListener("submit", function (e) {
				e.preventDefault();
				const userInput = document.getElementById("user-input");
				if (userInput.value.trim() !== "") {
					sendMessageToWorker(userInput.value.trim());
					userInput.value = "";
					searchResults.innerHTML = "";
				}
			});

		document
			.getElementById("user-input")
			.addEventListener("keydown", function (e) {
				if (e.key === "Escape") resetChatInterface();
			});
	}

	function handleChatTrigger() {
		talkBubble.classList.toggle("chat-active");
		mainContent.classList.toggle("chat-active");
		talkBubble.classList.contains("chat-active")
			? activateChatInterface()
			: (navPhrase.innerHTML = originalContent);
	}

	chatTrigger.addEventListener("click", handleChatTrigger);

	navPhrase.addEventListener("click", function (event) {
		if (event.target.tagName.toLowerCase() === "a") return;
		if (
			window.innerWidth < 840 &&
			!talkBubble.classList.contains("chat-active")
		) {
			handleChatTrigger();
		} else if (navPhrase.classList.contains("clickable")) {
			activateChatInterface();
			navPhrase.classList.remove("clickable");
		}
	});
});


		
			
			/**
 * A lightweight youtube embed. Still should feel the same to the user, just MUCH faster to initialize and paint.
 *
 * Thx to these as the inspiration
 *   https://storage.googleapis.com/amp-vs-non-amp/youtube-lazy.html
 *   https://autoplay-youtube-player.glitch.me/
 *
 * Once built it, I also found these:
 *   https://github.com/ampproject/amphtml/blob/master/extensions/amp-youtube (👍👍)
 *   https://github.com/Daugilas/lazyYT
 *   https://github.com/vb/lazyframe
 */
class LiteYTEmbed extends HTMLElement {
    connectedCallback() {
        this.videoId = this.getAttribute('videoid');

        let playBtnEl = this.querySelector('.lty-playbtn');
        // A label for the button takes priority over a [playlabel] attribute on the custom-element
        this.playLabel = (playBtnEl && playBtnEl.textContent.trim()) || this.getAttribute('playlabel') || 'Play';

        this.dataset.title = this.getAttribute('title') || "";

        /**
         * Lo, the youtube poster image!  (aka the thumbnail, image placeholder, etc)
         *
         * See https://github.com/paulirish/lite-youtube-embed/blob/master/youtube-thumbnail-urls.md
         */
        if (!this.style.backgroundImage) {
          this.style.backgroundImage = `url("https://i.ytimg.com/vi/${this.videoId}/hqdefault.jpg")`;
          this.upgradePosterImage();
        }

        // Set up play button, and its visually hidden label
        if (!playBtnEl) {
            playBtnEl = document.createElement('button');
            playBtnEl.type = 'button';
            playBtnEl.classList.add('lty-playbtn');
            this.append(playBtnEl);
        }
        if (!playBtnEl.textContent) {
            const playBtnLabelEl = document.createElement('span');
            playBtnLabelEl.className = 'lyt-visually-hidden';
            playBtnLabelEl.textContent = this.playLabel;
            playBtnEl.append(playBtnLabelEl);
        }

        this.addNoscriptIframe();

        // for the PE pattern, change anchor's semantics to button
        if(playBtnEl.nodeName === 'A'){
            playBtnEl.removeAttribute('href');
            playBtnEl.setAttribute('tabindex', '0');
            playBtnEl.setAttribute('role', 'button');
            // fake button needs keyboard help
            playBtnEl.addEventListener('keydown', e => {
                if( e.key === 'Enter' || e.key === ' ' ){
                    e.preventDefault();
                    this.activate();
                }
            });
        }

        // On hover (or tap), warm up the TCP connections we're (likely) about to use.
        this.addEventListener('pointerover', LiteYTEmbed.warmConnections, {once: true});
        this.addEventListener('focusin', LiteYTEmbed.warmConnections, {once: true});

        // Once the user clicks, add the real iframe and drop our play button
        // TODO: In the future we could be like amp-youtube and silently swap in the iframe during idle time
        //   We'd want to only do this for in-viewport or near-viewport ones: https://github.com/ampproject/amphtml/pull/5003
        this.addEventListener('click', this.activate);

        // Chrome & Edge desktop have no problem with the basic YouTube Embed with ?autoplay=1
        // However Safari desktop and most/all mobile browsers do not successfully track the user gesture of clicking through the creation/loading of the iframe,
        // so they don't autoplay automatically. Instead we must load an additional 2 sequential JS files (1KB + 165KB) (un-br) for the YT Player API
        // TODO: Try loading the the YT API in parallel with our iframe and then attaching/playing it. #82
        this.needsYTApi = this.hasAttribute("js-api") || navigator.vendor.includes('Apple') || navigator.userAgent.includes('Mobi');
    }

    /**
     * Add a <link rel={preload | preconnect} ...> to the head
     */
    static addPrefetch(kind, url, as) {
        const linkEl = document.createElement('link');
        linkEl.rel = kind;
        linkEl.href = url;
        if (as) {
            linkEl.as = as;
        }
        document.head.append(linkEl);
    }

    /**
     * Begin pre-connecting to warm up the iframe load
     * Since the embed's network requests load within its iframe,
     *   preload/prefetch'ing them outside the iframe will only cause double-downloads.
     * So, the best we can do is warm up a few connections to origins that are in the critical path.
     *
     * Maybe `<link rel=preload as=document>` would work, but it's unsupported: http://crbug.com/593267
     * But TBH, I don't think it'll happen soon with Site Isolation and split caches adding serious complexity.
     */
    static warmConnections() {
        if (LiteYTEmbed.preconnected) return;

        // The iframe document and most of its subresources come right off youtube.com
        LiteYTEmbed.addPrefetch('preconnect', 'https://www.youtube-nocookie.com');
        // The botguard script is fetched off from google.com
        LiteYTEmbed.addPrefetch('preconnect', 'https://www.google.com');

        // Not certain if these ad related domains are in the critical path. Could verify with domain-specific throttling.
        LiteYTEmbed.addPrefetch('preconnect', 'https://googleads.g.doubleclick.net');
        LiteYTEmbed.addPrefetch('preconnect', 'https://static.doubleclick.net');

        LiteYTEmbed.preconnected = true;
    }

    fetchYTPlayerApi() {
        if (window.YT || (window.YT && window.YT.Player)) return;

        this.ytApiPromise = new Promise((res, rej) => {
            var el = document.createElement('script');
            el.src = 'https://www.youtube.com/iframe_api';
            el.async = true;
            el.onload = _ => {
                YT.ready(res);
            };
            el.onerror = rej;
            this.append(el);
        });
    }

    /** Return the YT Player API instance. (Public L-YT-E API) */
    async getYTPlayer() {
        if(!this.playerPromise) {
            await this.activate();
        }

        return this.playerPromise;
    }

    async addYTPlayerIframe() {
        this.fetchYTPlayerApi();
        await this.ytApiPromise;

        const videoPlaceholderEl = document.createElement('div')
        this.append(videoPlaceholderEl);

        const paramsObj = Object.fromEntries(this.getParams().entries());

        this.playerPromise = new Promise(resolve => {
            let player = new YT.Player(videoPlaceholderEl, {
                width: '100%',
                videoId: this.videoId,
                playerVars: paramsObj,
                events: {
                    'onReady': event => {
                        event.target.playVideo();
                        resolve(player);
                    }
                }
            });
        });
    }

    // Add the iframe within <noscript> for indexability discoverability. See https://github.com/paulirish/lite-youtube-embed/issues/105
    addNoscriptIframe() {
        const iframeEl = this.createBasicIframe();
        const noscriptEl = document.createElement('noscript');
        // Appending into noscript isn't equivalant for mysterious reasons: https://html.spec.whatwg.org/multipage/scripting.html#the-noscript-element
        noscriptEl.innerHTML = iframeEl.outerHTML;
        this.append(noscriptEl);
    }

    getParams() {
        const params = new URLSearchParams(this.getAttribute('params') || []);
        params.append('autoplay', '1');
        params.append('playsinline', '1');
        return params;
    }

    async activate(){
        if (this.classList.contains('lyt-activated')) return;
        this.classList.add('lyt-activated');

        if (this.needsYTApi) {
            return this.addYTPlayerIframe(this.getParams());
        }

        const iframeEl = this.createBasicIframe();
        this.append(iframeEl);

        // Set focus for a11y
        iframeEl.focus();
    }

    createBasicIframe(){
        const iframeEl = document.createElement('iframe');
        iframeEl.width = 560;
        iframeEl.height = 315;
        // No encoding necessary as [title] is safe. https://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#:~:text=Safe%20HTML%20Attributes%20include
        iframeEl.title = this.playLabel;
        iframeEl.allow = 'accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture';
        iframeEl.allowFullscreen = true;
        // AFAIK, the encoding here isn't necessary for XSS, but we'll do it only because this is a URL
        // https://stackoverflow.com/q/64959723/89484
        iframeEl.src = `https://www.youtube-nocookie.com/embed/${encodeURIComponent(this.videoId)}?${this.getParams().toString()}`;
        return iframeEl;
    }

    /**
     * In the spirit of the `lowsrc` attribute and progressive JPEGs, we'll upgrade the reliable
     * poster image to a higher resolution one, if it's available.
     * Interestingly this sddefault webp is often smaller in filesize, but we will still attempt it second
     * because getting _an_ image in front of the user if our first priority.
     *
     * See https://github.com/paulirish/lite-youtube-embed/blob/master/youtube-thumbnail-urls.md for more details
     */
    upgradePosterImage() {
         // Defer to reduce network contention.
        setTimeout(() => {
            const webpUrl = `https://i.ytimg.com/vi_webp/${this.videoId}/sddefault.webp`;
            const img = new Image();
            img.fetchPriority = 'low'; // low priority to reduce network contention
            img.referrerpolicy = 'origin'; // Not 100% sure it's needed, but https://github.com/ampproject/amphtml/pull/3940
            img.src = webpUrl;
            img.onload = e => {
                // A pretty ugly hack since onerror won't fire on YouTube image 404. This is (probably) due to
                // Youtube's style of returning data even with a 404 status. That data is a 120x90 placeholder image.
                // … per "annoying yt 404 behavior" in the .md
                const noAvailablePoster = e.target.naturalHeight == 90 && e.target.naturalWidth == 120;
                if (noAvailablePoster) return;

                this.style.backgroundImage = `url("${webpUrl}")`;
            }
        }, 100);
    }
}
// Register custom element
customElements.define('lite-youtube', LiteYTEmbed);

			const style = document.head.appendChild(document.createElement('style'));
style.textContent = /*css*/`

  lite-vimeo {
    aspect-ratio: 16 / 9;
    background-color: #000;
    position: relative;
    display: block;
    contain: content;
    background-position: center center;
    background-size: cover;
    cursor: pointer;
  }

  lite-vimeo > iframe {
    width: 100%;
    height: 100%;
    position: absolute;
    top: 0;
    left: 0;
    border: 0;
  }

  lite-vimeo > .ltv-playbtn {
    font-size: 10px;
    padding: 0;
    width: 6.5em;
    height: 4em;
    background: rgba(23, 35, 34, .75);
    z-index: 1;
    opacity: .8;
    border-radius: .5em;
    transition: opacity .2s ease-out, background .2s ease-out;
    outline: 0;
    border: 0;
    cursor: pointer;
  }

  lite-vimeo:hover > .ltv-playbtn {
    background-color: rgb(0, 173, 239);
    opacity: 1;
  }

  /* play button triangle */
  lite-vimeo > .ltv-playbtn::before {
    content: '';
    border-style: solid;
    border-width: 10px 0 10px 20px;
    border-color: transparent transparent transparent #fff;
  }

  lite-vimeo > .ltv-playbtn,
  lite-vimeo > .ltv-playbtn::before {
    position: absolute;
    top: 50%;
    left: 50%;
    transform: translate3d(-50%, -50%, 0);
  }

  /* Post-click styles */
  lite-vimeo.ltv-activated {
    cursor: unset;
  }

  lite-vimeo.ltv-activated::before,
  lite-vimeo.ltv-activated > .ltv-playbtn {
    opacity: 0;
    pointer-events: none;
  }
`;

/**
 * Ported from https://github.com/paulirish/lite-youtube-embed
 *
 * A lightweight vimeo embed. Still should feel the same to the user, just MUCH faster to initialize and paint.
 *
 * Thx to these as the inspiration
 *   https://storage.googleapis.com/amp-vs-non-amp/youtube-lazy.html
 *   https://autoplay-youtube-player.glitch.me/
 *
 * Once built it, I also found these:
 *   https://github.com/ampproject/amphtml/blob/master/extensions/amp-youtube (👍👍)
 *   https://github.com/Daugilas/lazyYT
 *   https://github.com/vb/lazyframe
 */
class LiteVimeo extends (globalThis.HTMLElement ?? class {}) {
  /**
   * Begin pre-connecting to warm up the iframe load
   * Since the embed's network requests load within its iframe,
   *   preload/prefetch'ing them outside the iframe will only cause double-downloads.
   * So, the best we can do is warm up a few connections to origins that are in the critical path.
   *
   * Maybe `<link rel=preload as=document>` would work, but it's unsupported: http://crbug.com/593267
   * But TBH, I don't think it'll happen soon with Site Isolation and split caches adding serious complexity.
   */
  static _warmConnections() {
    if (LiteVimeo.preconnected) return;
    LiteVimeo.preconnected = true;

    // The iframe document and most of its subresources come right off player.vimeo.com
    addPrefetch('preconnect', 'https://player.vimeo.com');
    // Images
    addPrefetch('preconnect', 'https://i.vimeocdn.com');
    // Files .js, .css
    addPrefetch('preconnect', 'https://f.vimeocdn.com');
    // Metrics
    addPrefetch('preconnect', 'https://fresnel.vimeocdn.com');
  }

  connectedCallback() {
    this.videoId = this.getAttribute('videoid');

    /**
     * Lo, the vimeo placeholder image!  (aka the thumbnail, poster image, etc)
     * We have to use the Vimeo API.
     */
    let { width, height } = getThumbnailDimensions(this.getBoundingClientRect());
    let devicePixelRatio = window.devicePixelRatio || 1;
    if (devicePixelRatio >= 2) devicePixelRatio *= .75;
    width = Math.round(width * devicePixelRatio);
    height = Math.round(height * devicePixelRatio);

    fetch(`https://vimeo.com/api/v2/video/${this.videoId}.json`)
      .then(response => response.json())
      .then(data => {
        let thumbnailUrl = data[0].thumbnail_large;
        thumbnailUrl = thumbnailUrl.replace(/-d_[\dx]+$/i, `-d_${width}x${height}`);
        this.style.backgroundImage = `url("${thumbnailUrl}")`;
      });

    let playBtnEl = this.querySelector('.ltv-playbtn');
    // A label for the button takes priority over a [playlabel] attribute on the custom-element
    this.playLabel = (playBtnEl && playBtnEl.textContent.trim()) || this.getAttribute('playlabel') || 'Play video';

    if (!playBtnEl) {
      playBtnEl = document.createElement('button');
      playBtnEl.type = 'button';
      playBtnEl.setAttribute('aria-label', this.playLabel);
      playBtnEl.classList.add('ltv-playbtn');
      this.append(playBtnEl);
    }
    playBtnEl.removeAttribute('href');

    // On hover (or tap), warm up the TCP connections we're (likely) about to use.
    this.addEventListener('pointerover', LiteVimeo._warmConnections, {
      once: true
    });

    // Once the user clicks, add the real iframe and drop our play button
    // TODO: In the future we could be like amp-youtube and silently swap in the iframe during idle time
    //   We'd want to only do this for in-viewport or near-viewport ones: https://github.com/ampproject/amphtml/pull/5003
    this.addEventListener('click', this.addIframe);
  }

  addIframe() {
    if (this.classList.contains('ltv-activated')) return;
    this.classList.add('ltv-activated');

    const iframeEl = document.createElement('iframe');
    iframeEl.width = 640;
    iframeEl.height = 360;
    // No encoding necessary as [title] is safe. https://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#:~:text=Safe%20HTML%20Attributes%20include
    iframeEl.title = this.playLabel;
    iframeEl.allow = 'accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture';
    // AFAIK, the encoding here isn't necessary for XSS, but we'll do it only because this is a URL
    // https://stackoverflow.com/q/64959723/89484
    iframeEl.src = `https://player.vimeo.com/video/${encodeURIComponent(this.videoId)}?autoplay=1`;
    this.append(iframeEl);

    // Set focus for a11y
    iframeEl.addEventListener('load', iframeEl.focus, { once: true });
  }
}

if (globalThis.customElements && !globalThis.customElements.get('lite-vimeo')) {
  globalThis.customElements.define('lite-vimeo', LiteVimeo);
}

/**
 * Add a <link rel={preload | preconnect} ...> to the head
 */
function addPrefetch(kind, url, as) {
  const linkElem = document.createElement('link');
  linkElem.rel = kind;
  linkElem.href = url;
  if (as) {
    linkElem.as = as;
  }
  linkElem.crossorigin = true;
  document.head.append(linkElem);
}

/**
 * Get the thumbnail dimensions to use for a given player size.
 *
 * @param {Object} options
 * @param {number} options.width The width of the player
 * @param {number} options.height The height of the player
 * @return {Object} The width and height
 */
function getThumbnailDimensions({ width, height }) {
  let roundedWidth = width;
  let roundedHeight = height;

  // If the original width is a multiple of 320 then we should
  // not round up. This is to keep the native image dimensions
  // so that they match up with the actual frames from the video.
  //
  // For example 640x360, 960x540, 1280x720, 1920x1080
  //
  // Round up to nearest 100 px to improve cacheability at the
  // CDN. For example, any width between 601 pixels and 699
  // pixels will render the thumbnail at 700 pixels width.
  if (roundedWidth % 320 !== 0) {
    roundedWidth = Math.ceil(width / 100) * 100;
    roundedHeight = Math.round((roundedWidth / width) * height);
  }

  return {
    width: roundedWidth,
    height: roundedHeight
  };
}
</script>